{"title": "$AMD shares up 8% following rollout of new MI300 AI chips", "selftext": "AMD shares surged over 8% after the launch of its latest AI chip, the Instinct MI300, with major players like Microsoft, Meta, and OpenAI set to utilize it. AMD CEO Lisa Su hailed the MI300 as the world's highest-performance accelerators for generative AI. The company forecasted MI300 sales to bring in $2 billion in revenue for 2024.\n\n[https://www.investopedia.com/amd-stock-surges-with-microsoft-meta-and-openai-set-to-use-its-latest-ai-chip-8411853](https://www.investopedia.com/amd-stock-surges-with-microsoft-meta-and-openai-set-to-use-its-latest-ai-chip-8411853)", "id": "18d136b", "created_utc": 1701971203.0, "score": 536, "upvote_ratio": 0.97, "num_comments": 87, "comments": [{"body": "Basically it dropped from $123ish to $117ish before the announcement yesterday. Currently at $128. 52 week high is $132.", "score": 108, "replies": [{"body": "Notably, there was no significant market reaction yesterday after the announcement, during market hours. A day later, market decides it was good. (There were a couple modest upgrades I believe, but that doesn't usually move a stock too much.)", "score": 47, "replies": [{"body": "Same with Google, I saw the Gemini news one day before the stock shot up. Maybe fund managers reacting manually and slowly to it, instead of algos?", "score": 2, "replies": []}]}, {"body": "[deleted]", "score": -9, "replies": [{"body": "[deleted]", "score": 8, "replies": [{"body": "You gotta type in all caps so he can hear you better.", "score": 9, "replies": []}]}]}]}, {"body": "The competition has begun. I hope it can break Nvidia domination, so companies have more options in the market.", "score": 197, "replies": [{"body": "Everyone keeps talking about how Jensen's planning is always 5 years ahead of the competition. Now is the time to prove it. \n\nWill be interesting to see how this plays out. I wish I could be more excited about this AI hype, but just can't get rid of the sense that we are getting way ahead of ourselves.", "score": 63, "replies": [{"body": "Definitely way ahead of ourselves", "score": 11, "replies": [{"body": "Ignore the narrative.  Just swing the price action", "score": 3, "replies": []}]}]}, {"body": "As AI models become more efficient and there is wider availability of smaller open source models that can be run on personal devices without requiring massive server-side infrastructure, there might not be as much need for new semiconductors either. A lot of new growth has been priced in, the question is whether it will all be needed.", "score": 11, "replies": [{"body": "The foundational LLMs will only get larger. But the smaller models derived from the foundational large models are quite good. However even the small models will grow in size as they get more sophisticated and the adoption grows.", "score": 8, "replies": [{"body": "LLM inference doesn't need as much compute power to run as everyone thinks. But it needs fast HBM GPU memory. The bottleneck is the memory bandwidth and how much memory you have. It will take some time, but hardware will catch up and it won't exclusively be nvidia. Actually one of the most economic devices to run >100gb models without a GPU cluster is apples mac studio, because it uses HBM as system memory.", "score": 3, "replies": []}]}, {"body": "Can you run an LLM on a personal device? No. This is dependent on how pervasive LLMs will become", "score": 2, "replies": [{"body": "Yes. Google just announced Gemini Nano that runs on the Pixel.", "score": 6, "replies": [{"body": "‚ÄúMini LLM‚Äù feels like they‚Äôre playing on the LLM hype here without using an LLM. You can‚Äôt have language based inferences without the massive models currently used. (Unless they had an incredible break through which I doubt they did, otherwise there would be one level of Gemini provided.. the smallest one)", "score": 2, "replies": [{"body": "I do research within Deep Learning, not specifically LLMs, but LLMs are deep learning too. Generally, inference requires much much less computing resources than training. With a mini-LLM, I can definitely see it being able to run on a mobile locally, considering how powerful some of the phones are getting lately.", "score": 3, "replies": []}]}]}, {"body": "Yes, you can run them on a personal device.", "score": 3, "replies": []}, {"body": "I run 7 billion parameter open source LLMs on my lowest grade possible macbook air. \n\nThese models are reasonably effective too, capable of quite a lot without even an internet connection.", "score": 3, "replies": [{"body": "For comparison, GPT 4 is at 1.75 trillion parameters", "score": 1, "replies": []}]}]}, {"body": "Of course you need more GPU. Inference is extremely slow. GPT4 inference requires 8 A100s I believe to have reasonable response time.", "score": 1, "replies": []}, {"body": "The fuxk u talking about?ai market is gwrowing 30 percent every year over the next 10 years", "score": 1, "replies": []}, {"body": "Doubtful. It's like saying in 1997 that computers wont need more than a few Mbs of storage", "score": 1, "replies": []}]}, {"body": "Haha\n\nHaha\n\nNo", "score": -8, "replies": []}, {"body": "CUDA vs Open source. NVIDIA might have an advantage after working on it for two decades", "score": 0, "replies": []}, {"body": "I just wish AMD would get their shit together with gaming cards at the high end so Nvidia would feel at least a little pressure. They need to add hardware to accelerate ray-tracing/upscaling", "score": -6, "replies": [{"body": "AMD offers pretty good consumer GPUs, if you're a Linux user like myself, going AMD is a no brainer. But when it comes to competing at the high end, AMD doesn't have the marketshare to do it. Because outspending Nvidia on the big monolythic GPU dies is a losing proposition.\n\nWhich is why AMD's chiplet strategy is key. \n\nChiplets are difficult to pull off. This is because breaking up the GPU into chiplets introduces latencies. Which is particularly problematic for graphics as opposed to compute.\n\nHowever bit by bit AMD has been innovating here, and a recent Patent suggests they have cracked the code. If they can scale chiplets in consumer graphics GPUs, this lowers the barrier of entry significantly. And we will for sure see some change there.", "score": 7, "replies": []}, {"body": "AMD had good cards, but nVidia has better software and sadly software can be a massive money drain... I'd rather AMD focuses on things making money first and foremost, rather then chasing nVidia and burning themselves out.", "score": 5, "replies": []}]}]}, {"body": "[deleted]", "score": 73, "replies": [{"body": "It's reasonable to think that the real money won't move until there's at least 1 PowerPoint made for \nFund managers explaining what all the gobbledygook means.", "score": 41, "replies": [{"body": "[deleted]", "score": 9, "replies": [{"body": "I would say it's more that this is their job, and it would be irresponsible to not leverage in house specialists to distill conclusions/risks/implications.\n\nThese products are the output of thousands of top scientists, arguably the most complicated products sold in the world (excluding ASML machines). \n\nThe perspective of those who can understand the product from the bottom up, and practices inside the firm that may colour the trajectories, would be critical in accurately pricing the equities.", "score": 17, "replies": [{"body": "[deleted]", "score": -4, "replies": [{"body": "They not take anything at face value cuz they are not fools,and u should not either", "score": 4, "replies": []}]}]}, {"body": "No one is a expert on everything\n\nWhat if I dropped you in front of a major farming expo presentation? Or one about pharmaceuticals?", "score": 5, "replies": [{"body": "[deleted]", "score": -1, "replies": [{"body": "People can and do announce shit all the time and it doesnt always live up to the hype", "score": 1, "replies": []}]}]}, {"body": "Yes.", "score": 3, "replies": []}]}]}, {"body": "The street needed to hear it from CNBC to know it was bullish\n\nü§°", "score": 6, "replies": []}, {"body": "FOMO IS A MOFO", "score": 2, "replies": []}, {"body": "That‚Äôs pretty typical for AMD. I remember quite a few ER‚Äôs where the stock stayed the same or dropped the day after but after the articles and headlines came out 24 hours later it popped. Market is slow on the uptake of good news for AMD I guess.", "score": 2, "replies": []}, {"body": "It's almost like its the idiots of the mainstream media that are keeping this shit show alive because they don't know how to not buy hype.", "score": 2, "replies": [{"body": "[deleted]", "score": 5, "replies": [{"body": "P/E ratio says otherwise lmao", "score": 0, "replies": [{"body": "Yea, people are just hoping that they buy the hype so they can sell the hype they bought.\n\nAMD and NVIDIA can never come close to producing the profits required to cover even half their PE ratio.\n\nEveryone got conned, and made a bunch of people really rich. They are just hoping they can get something back.", "score": 2, "replies": []}]}]}]}, {"body": "Most market reactions to any number of events don't really work themselves out till the next day.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Not the sensible reactions.", "score": 1, "replies": []}]}]}]}, {"body": "To whoever I sold my $108 call to, enjoy it mfer", "score": 45, "replies": [{"body": "ü§°", "score": -5, "replies": []}, {"body": "Why would you sell a call with the ai fervor", "score": 1, "replies": []}]}, {"body": "Been in since 2017 @ $14.50/share when I read the first Ryzen reviews", "score": 34, "replies": [{"body": "I was too at with about 860 shares at around $15. I'm kicking my self hard right now for selling at 20.", "score": 4, "replies": [{"body": "Sup, I was in at $6 in 2016 and sold at $12 like six months later", "score": 3, "replies": [{"body": "the guys I know who bought in high 1$ range sold when it hit the teens and I told him, you'll regret selling (back in 2017)...", "score": 2, "replies": []}]}]}, {"body": "Nice. I didn't have the fortitude, and went in and out. It would have been nice to just hold on. I was there when AMD went to $4 due to THATIC investment news.", "score": 2, "replies": []}, {"body": "I bought at that time as well.. Then sold at $30üôÉüôÉ", "score": 1, "replies": []}]}, {"body": "Sue bae", "score": 28, "replies": []}, {"body": "Nvidia has been dominating this space for the last few years. I've luckily bought quite a few shared of AMD 5 years ago so hoping they can capture more market share with this", "score": 9, "replies": []}, {"body": "Don't bet against Lisa Sue!", "score": 9, "replies": []}, {"body": "What is their alternative to CUDA?", "score": 13, "replies": [{"body": "OpenAI and PyTorch have this framework called Triton which can be used as an alternative to CUDA to program GPUs.", "score": 17, "replies": []}, {"body": "ROCm, the 6th version was announced yesterday and will be launching with MI300", "score": 27, "replies": [{"body": "ROCm is looking fairly weak against CUDA thought", "score": 6, "replies": []}]}, {"body": "Nothing that is the biggest issue, amd always does this and then abandons. Until rocm is stable and the performance in pytorch is on par with Cuda it will always be runner up.", "score": 3, "replies": []}]}, {"body": "God bless semiconductors", "score": 7, "replies": []}, {"body": "Lisa loves an uphill battle, in since 2013, man what a ride it‚Äôs been!", "score": 4, "replies": []}, {"body": "I bought AMD at $5. Sold it at $20... Lmao, fuck me.", "score": 5, "replies": [{"body": "Probably better than most retailers anyway. Many bought after the previous rally couple of years ago and then lost hope and sold on the way the down.", "score": 3, "replies": []}]}, {"body": "https://i.imgur.com/JQH9Lh5.png\n\nsold it all today, thx for the ride AMD", "score": 28, "replies": [{"body": "Jesus, the guy makes a nice profit and you people are all like ‚ÄòTOO SOON‚Äô\n\nAnd here I thought this sub was about making money, not just HODLing forever. \n\nCan‚Äôt you people just be happy for someone?", "score": 22, "replies": []}, {"body": "congrats. Thought about shedding some shares but I decided not to since this first time they have a real product to roll out that can compete vs nvidia. It has just begun imo. \n\n$2B is pretty tame estimates. Lisa if my memory serves me right always prefers to underpromise and overdeliver in numbers. Time will tell.", "score": 12, "replies": [{"body": "yea I had options, and 500 shares, decided to just cut loose and be happy", "score": 6, "replies": []}]}, {"body": "I bought last year from $100 and added all the way down to $55. Lightened up a little today.", "score": 2, "replies": []}, {"body": "Big mistake", "score": -7, "replies": [{"body": "Yea 70k profit is such a mistake, i would never!", "score": 6, "replies": [{"body": "I mean, depending on why you're selling it could be.\n\nThis is just the beginning for AMD.", "score": 2, "replies": [{"body": "160 by 12/29/23", "score": 1, "replies": []}]}]}]}, {"body": "Way to cash out!", "score": 1, "replies": []}, {"body": "same hereü´°‚ú®", "score": 1, "replies": []}]}, {"body": "Every Coke (NVDA) needs it's Pepsi (AMD). :)", "score": 7, "replies": []}, {"body": "Lisa been earning that bonus", "score": 5, "replies": []}, {"body": "Nividia Killer!!", "score": 3, "replies": []}, {"body": "Hard to see how they can compete without CUDA", "score": 6, "replies": [{"body": "They just bought a software/ai company to help with improving their software solution to CUDA.", "score": 2, "replies": [{"body": "The success of CUDA is that it is embedded to the hardware level. It is hard to see how an outsider can help what insider cannot do.", "score": 2, "replies": [{"body": "How is AMD an outsider for their own chips? It‚Äôs their own software that they created.", "score": 5, "replies": [{"body": "I mean if they need to ‚Äúbought ‚Äú a company, then it shows their internal effort failed", "score": 2, "replies": []}]}]}]}]}, {"body": "Good to finally see some competition but it seems like it‚Äôs a small part of the ecosystem. There should be a market for lower cost low to medium end chips for AI. Not everyone needs a H100.", "score": 1, "replies": []}, {"body": "[deleted]", "score": -7, "replies": []}, {"body": "\"400 billion AI market\". That makes zero sense. The entire semiconductor market is declining and is $520 billion.\n\nThe entire semiconductor market is supposed to double in 4 years because of \"AI AI AI AI AI\"?\n\nMaybe if you reclassify the old semiconductor market as \"AI\" the math might work. It's not going to be a semiconductor market of $520 billion and a new \"AI\" market of $400 billion.", "score": -5, "replies": []}, {"body": "If Lisa needs to brag that much about a new release, it's time to load puts", "score": -2, "replies": []}, {"body": "how is this not bearish for nvidia?", "score": 1, "replies": []}]}
