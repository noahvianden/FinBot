{"title": "Vehicle control is the final piece of the Tesla FSD AI puzzle. That will drop >300k lines of C++ control code by ~2 orders of magnitude. It is training as I write this. Our progress is currently training compute constrained, not engineer constrained.", "selftext": "", "id": "15fx7rm", "created_utc": 1690945897.0, "score": 102, "upvote_ratio": 0.89, "num_comments": 101, "comments": [{"body": ">Our progress is currently training compute constrained, not engineer constrained.\n\n\nSo this is what Elon meant when he said FSD has been \"solved\". They already figured out the solution, only thing missing is finishing implementation. We will likely get a very nice Christmas present this year, in term of FSD and TSLA stock price.", "score": 31, "replies": [{"body": "As someone who works in this field that‚Äôs not how it works. It‚Äôs making progress training until it doesn‚Äôt, then you have to figure out why.\n\nYou don‚Äôt know it‚Äôs solved until it works, simple as that", "score": 110, "replies": [{"body": "Came to say this.\nThis is why Elon‚Äôs estimates are always wrong. He sees every good step as the final one, before we even take it.\n\nDon‚Äôt count your eggs before they hatch.", "score": 36, "replies": [{"body": ">Don‚Äôt count your eggs before they hatch.\n\n\nDon't count your x* before they hatch. We're trying to do away with the bird stuff /s.", "score": 18, "replies": [{"body": "Putting hard-working union birds out of work, huh? Have you even spoken to the leadership over at Bird local 468?", "score": 3, "replies": []}]}, {"body": "Yes that's exactly it, while I do think a bunch of if-else statements won't cover every edge cases (the 300K lines of code) and ML is the way to go, there is no guarantee they will have it trained the right way anytime soon.\nStill, this is a step in the right direction IMO.", "score": 2, "replies": [{"body": "Ya, at least finish training and try it a bit before making promises.", "score": 1, "replies": []}]}]}, {"body": "lol 'someone who works in this field' knows what it means to simply be blocked waiting for hardware to do stuff.\n\nHe's saying if you doubled his engineering team, it wouldn't get done much faster, but if you doubled his compute, it would get done faster.\n\nThat does NOT diminish the importance of the engineering team.\n\nAt much-less-important stuff, I've literally been blocked in this manner in real life before where I was waiting for our machines to complete processes before I could get more work done.\n\nIf my machines were faster, I'd get more work done. If there were two of me I would not have gotten more work done.", "score": 13, "replies": [{"body": "Sure. He is waiting for the machine to do stuff. This is correct. I've encountered the exact same thing. Imagine an integration test being blocked because of whatever (congestion, hardware failure, just too slow). \n\nThat doesn't mean you are done, of course. Your integration test will often discover issues that need to be resolved. Sometimes, hopefully rarely, those issues are significant and take meaningful time to resolve. \n\nBut this is further from the finish line than even that. They have a model they are training. They believe this model will solve for vehicle control and remove all the hacked together if and case statements in the control loop. BUT - they cannot know that with certainty until they training starts to peak. \n\nPeople assuming a \"very nice Christmas present\" may be jumping the gun because we don't know where the model training peaks. We can't know that until training starts to peak. If the model training peaks at a 15-year-old, 1-month experienced driver, it's a no-go. If the model training peaks at 85 percent of use cases are green but 10 are yellow and 5 are red, then its a no-go.\n\nIf it peaks before their required success criteria, the model has to be rethought and retrained...or control code needs to be hacked over the model outputs.", "score": 11, "replies": [{"body": "I agree 100% with what you said but I don't think it contradicts with the idea \"We are compute constrained, not engineer constrained\"\n\nElon made 2 claims:  \n1. We are VERY CLOSE to DONE  \n2. Our bottleneck is compute, not engineers\n\nYou spoke to and I agree that #1 is something he can't know/has been wrong about 100x and I think #2 could be true at the same time.", "score": 3, "replies": [{"body": "The number of times in my professional career I have heard \"code is done\" when either it :\n\na) clearly isn't - the devs are lying\n\nb) their definition of done means code is written and because we're the dogs nuts we just know it's going to work (aka we're done why is testing taking so long or \"you didn't tell us it had to do \\*that\\*\")\n\nIt's up there with we're 80% done and on track and even though we've used up 90% of available time it will still be ready on time.", "score": 2, "replies": []}]}]}]}, {"body": "My bet is that they are training it against the latest development version of the C++ code. Run them in parallel and when the AI does something the C++ code doesn't, it's a fail. A few billion tries and the NN learns the behavior.\n\nIf that's what they're doing, it'll develop quickly until it's 99% as good as the C++ code, then they're back to gathering training clips from the fleet to push it further. \n\nThat's just my speculation, though.", "score": 4, "replies": [{"body": "I sure hope not. It would be learning a lot of crappy behavior", "score": 2, "replies": [{"body": "It would also be learning a lot of very good behavior in a lot of areas. The NN has to learn the very basics before it can get into the more difficult stuff.", "score": 1, "replies": [{"body": "I just think it would be better to learn from actual drivers. Even the worst drivers are better than FSD. Why start at a disadvantage?", "score": 2, "replies": [{"body": "Speed. You can go from 0 to \"caught up with the old one\" very fast this way, then they can improve from there using actual driver's clips.", "score": 1, "replies": [{"body": "If V12 comes out, and it keeps making the same stupid mistakes that it‚Äôs been making since the beginning, I‚Äôll be so angry that you were right. But I hope they‚Äôre smarter than that", "score": 1, "replies": [{"body": "v11 builds the training matrix to catch v12 up from nothing, then they start applying the video clips from human drivers with v11 so it can surpass v11, then they release it as v12 and people get impressed.\n\nThat's my prediction.", "score": 2, "replies": []}]}]}, {"body": "No, the worst drivers are definitely not better than FSD. I can tell you that for a FACT.", "score": 1, "replies": [{"body": "In my area, I have to stop FSD from getting in accidents multiple times per week. No human driver would still have their license or be alive if they were that bad", "score": 2, "replies": [{"body": "Does your do 80 on the wrong side of the highway? Because that's what the worst drivers who are on drugs and/or alcohol do all the time.", "score": 1, "replies": [{"body": "I‚Äôd be fine with Tesla also not using those people in their training data", "score": 1, "replies": []}]}]}]}]}]}]}]}, {"body": "I think you're missing the context.  \n\n> We over-complicated the problem, Tesla has figured out a simpler answer, too dumb to realize what the simple answer was. - Elon\n\nI believe this is what the \"solved\" is referring to.", "score": 1, "replies": []}, {"body": "Elon has been personally testing V12 alpha so he knows it works", "score": -13, "replies": [{"body": "It's important to look at his historical statements on FSD before getting as excited as you sound right now.\n\nHere's a good site for historical FSD statements by Elon:\nhttps://motherfrunker.ca/fsd/\n\nAnd here's my personal favorite one, which led me to buy a Tesla with FSD the same month:\n\nFebruary 2019\n\n\"We will be feature complete full self driving this year. The car will be able to find you in a parking lot, pick you up, take you all the way to your destination without an intervention this year. I'm certain of that. That is not a question mark. It will be essentially safe to fall asleep and wake up at their destination towards the end of next year\"\n\nThis time will certainly be different.", "score": 11, "replies": [{"body": "He has been so ridiculously wrong about FSD, makes you question whether it was done on purpose to put a fire under the engineer's asses.", "score": 2, "replies": [{"body": "At this point even engineers are probably aware that missing the deadline is completely okay so it probably doesn't have any effect since missing the deadline doesn't seem to have consequences.", "score": 1, "replies": [{"body": "The boy who cried FSD", "score": 1, "replies": []}]}]}]}, {"body": "He said that about every big release that its mindblowing.", "score": 27, "replies": []}, {"body": "If it already works, why does it need additional training?\nStop drinking the Elon cool-aid. He's been wrong every time so far, and nothing indicates he is not wrong this time too", "score": 3, "replies": []}, {"body": "How much does he actually drive? He seems to spend most waking hours tweeting and rewteeting.", "score": 0, "replies": []}]}, {"body": "As someone who works in that field, too, I can only agree with you.\n\nThe idea that you can \"guess\" you are 10% from perfection and then just need 10% more work is hilarious, or in technical terms: BS.", "score": 0, "replies": []}, {"body": "Agreed you hit local maximums you didn‚Äôt anticipate and that is why predicting when it will be completed is impossible.\n\nHowever at some point you have to know you know there isn‚Äôt much left outside of whatever the last local maximum was.", "score": 1, "replies": []}, {"body": "Elon: \"It's solved!\" ^*    \n&nbsp;    \n&nbsp;    \n^* ^Investor ^Disclaimer: ^yadda ^yadda ^yadda ^\"forward ^looking ^statements\"", "score": 1, "replies": []}, {"body": "Small matter of training ![gif](emote|free_emotes_pack|grin)", "score": 1, "replies": []}, {"body": "The larger point, the investor point, is maybe Musk should stop shredding his credibility with these predictions. Bad for company. Bad for stock. Bad advertising. I know: he won‚Äôt stop.", "score": 1, "replies": []}]}, {"body": "Impossible to know it will work. Just another Q3 FSD promise. Dude does this every single year", "score": 8, "replies": []}, {"body": "Training can take time if you don't have the processing power. You literally can run servers for years 24/7 training.\n\nGranted Tesla basically has a super computer now so they are one of the few corporations that can do this.", "score": 2, "replies": []}, {"body": ">  They already figured out the solution, only thing missing is finishing implementation.\n\nOh come on, no one can know they figured out the solution until it's solved. He's been saying this in some form \"game set match\" \"we just need to feed it more data\" since what, 2017.", "score": 2, "replies": []}, {"body": "\"Tesla is supply constrained\" \"Demand is infinite\" \"Robo taxi by end of 2020\"", "score": 12, "replies": [{"body": "\"Nobody wants electric cars. They're glorified golf carts.\" \n\n\"Even if people wanted them, you can't make money on them.\" \n\n\"You can't start a new car company in America; it hasn't been done in 60 years.\" \n\n\"You can't road trip in an electric car. There's nowhere to charge and it takes too long.\" \n\nThis is a fun game!", "score": 5, "replies": []}, {"body": "When he says demand is infinite, he clearly means at a given price point. Obviously as prices move, so does demand. You either don't understand economics or you're being disingenuous on purpose.", "score": 5, "replies": [{"body": "![gif](giphy|l4Ki2obCyAQS5WhFe)", "score": 3, "replies": []}, {"body": "Lol what is the point of saying ‚Äúdemand is infinite‚Äù then?  Obviously people will buy a car that cost 50 dollars, but a car doesn‚Äôt cost 50 dollars to make.\n\n‚ÄúDemand is infinite‚Äù clearly meant he thought they would have infinite demand at the current price point, which is obviously not true.  \n\nBacktracking that to say ‚Äúdemand is infinite if the cars cost zero‚Äù is just weird coping behavior to justify a very stupid quote.", "score": 1, "replies": [{"body": "I missed it then, did people stop demanding Teslas?", "score": 3, "replies": [{"body": "no of course not demand is infinite like elong said -- thats why tesla doesn't advertise and has incredibly long lead times on cars and doesn't have to do margin impacting price cuts.\n\nyou definitely cannot order a tesla and have it delivered same month right now and they definitely haven't cut prices since last year to induce demand and they definitely haven't offered teasers like FSD transfers and they definitely haven't seen margin compression as a result of demand slowdowns.", "score": 3, "replies": []}]}]}]}, {"body": "Exactly that's why they never need to run ads... wait a minute", "score": 1, "replies": []}]}, {"body": "Yer totally bro.", "score": 2, "replies": []}, {"body": "Elon lies. It‚Äôs default mode of speech unless he actively chooses to speak truth.", "score": -1, "replies": []}, {"body": "Yes exactly. FSD has been \"solved\". It just needs to actually happen. (Probably within the next 10-25 years)", "score": 0, "replies": []}, {"body": "O sweet child you must be new here", "score": 0, "replies": []}]}, {"body": "Isn't it always compute constrained since the dawn of computing?  Back when I was in college we already know neural network is the way, we just didn't think we'll ever have the exponential compute power for NP.", "score": 7, "replies": [{"body": "No, not necessarily. You could be data constrained quite easily, which is likely what any competitor who goes the neural network route is going to experience.", "score": 19, "replies": [{"body": "Or talent constrained. Neural net is mostly understood, but my understanding is there is still an art to it. There is a lot less research in data curation and building the right tools to annotate quickly also requires talent.", "score": 8, "replies": [{"body": "Well, NNs are largely understood, but specific architectures aren't necessarily. \n\nWe know Tesla uses transformers, but transformers still have hyperparameters, depth of model, learning rate etc.\n\nSo it's not like you simply have the data, open pytorch and away you go.\n\nPoint is you still need very smart individuals who contribute to model architecture.\n\nI agree with your point on data curating, Tesla's autolabeller is a massive deal that doesn't get enough attention (no pun intended).", "score": 9, "replies": [{"body": "I think it's safe to say we understand how to build and shape neural networks, but that has absolutely nothing to do with understanding how they'll perform.  \n\n\nShow the best expert in the world a novel architecture and I promise you they won't be able to tell you if it's going to be better or worse than SOTA without actually training it and testing it.  \n\n\nML is trial and error all the way down, including the network shape and architecture. A great example is the recent YOLO-NAS architecture. All they did was take an existing network architecture (YOLO6/8) and let another machine learning model make adjustments to the architecture and that resulted in a new SOTA architecture. Literally just let AI tweak the architecture, and boom: better results. No humans involved in making architecture decisions at all... machine learning inception.", "score": 1, "replies": []}]}, {"body": ">Neural net is mostly understood, but my understanding is there is still an art to it.\n\nEh, they're not really 'understood' in a general sense. Certain architectures are sorta understood as to what they're good at, like the attention mechanisms in transformers are clearly useful for building contextual links between symbols in a series, but that doesn't mean we just understand everything there is to know about neural networks in general.  \n\n\nSomeone could release a completely different NN architecture tomorrow that blows transformers out of the water when it comes to LLMs and it wouldn't really surprise anyone in the research field, IMO.", "score": 1, "replies": []}]}]}, {"body": "When were you in college? If it was after 2015 then yeah your point probably stands. Anything before then and it wasn‚Äôt so certain.\n\nNo one was publishing on NN in the late 90s, it was all support vector machines.", "score": 2, "replies": [{"body": "I'm old like turning in your assignment on a floppy old.  We talked about NN, it's not new, we just didn't think we can do it.", "score": 2, "replies": [{"body": "My professor in the mid 90s wanted us to do a project with NNs. He thought long term this was the way to go.", "score": 2, "replies": [{"body": ">He thought long term this was the way to go.\n\nThere are a few of us who have believed in them for a long time. The similarities between animal brains and the simplicity of having lots of individual nodes perform simple operations seems like it's fundamental to nature. I've never NOT believed this was the path forward for computing, but when you're not in active research it's hard to believe that with conviction until you start seeing real results, of which we definitely have these days.", "score": 1, "replies": []}]}, {"body": "Yes NN we‚Äôre discovered in the 60s, but it‚Äôs never been certain that it was the path forward until recently, that‚Äôs why other techniques of machine learning consumed most of the research effort in the 50 years from the 1960s to 2012 or so. We only really realized it could be the solution in the past decade.", "score": 2, "replies": []}]}]}, {"body": "Yes technically we are always computing constrained. If we had infinite amount of computing power AGI could be solved today. But since we don't have infinite amount of computing power we need to rely on engineers to create solutions to lessen the computing power required to reach the desired goal so that is is reachable with today's standards and in reasonable time.", "score": 1, "replies": []}, {"body": "Remember that labeling of the camera frames used to be done by humans?  It‚Äôs not hard at all to see that used to be the bottleneck, and not compute.", "score": 1, "replies": []}]}, {"body": "When looking at the possible compute in 1 or even 2 years, it really looks like FSD gets solved by then. We will have 10x and then 10x compute again. What we today have is quite tiny", "score": 4, "replies": []}, {"body": "#2weeks", "score": 1, "replies": []}, {"body": "Yea that‚Äôs not remotely true. There‚Äôs lots of engineering left.", "score": 0, "replies": [{"body": "He didn‚Äôt say there was no engineering left, simply that training cycles are the constraining factor.  Are you from Bloomberg news or something?  Reading comprehension please.", "score": 11, "replies": []}, {"body": "he's saying the bottleneck is compute\n\nso in other words:-if you tripled his engineering team, it would not get done much faster-if you tripled his compute, it would get done faster\n\nThat is totally believable.\n\nHis employees, which he has many and he says they are great, are often blocked waiting for the training to finish.", "score": 8, "replies": []}]}, {"body": "must have switched it to comma.ai, hotz is like yis! lol", "score": -1, "replies": []}, {"body": "That‚Äôs a poor statement.\n\nIt‚Äôs like‚Ä¶ look at sorting algorithms.\n\nYou can create your own very quickly and have it perform terribly. Than give it a massive set of data to sort, estimated time: 1 year\n\n‚ÄúIt‚Äôs compute constrained‚Äù\n\nOr maybe you can work out a quicker algorithm and have speed up the time by orders of magnitude.", "score": -6, "replies": []}, {"body": "I though this was supposed to be driving coast to coast 2016, and robotaxis end of 2020. \n*", "score": -1, "replies": []}, {"body": "Hey, richest man in the world, how about spending the money like all other automakers do to do the testing and software development on a private track or road rather than endangering all road users without their consent or permission.", "score": -19, "replies": [{"body": "How many incidents per milion miles caused by FSD on public roads ?", "score": 7, "replies": [{"body": "USA govt says 17 or 18 autonomous deaths were in teslas", "score": -14, "replies": [{"body": "Ironically there are 80% less accidents when FSD is engaged then when it‚Äôs not engaged", "score": 3, "replies": [{"body": "I guess. As long as you dont die.", "score": -4, "replies": [{"body": "Safer than you driving ü§∑üèª‚Äç‚ôÇÔ∏è", "score": 2, "replies": []}]}]}, {"body": "That does not include where FSD was activated, only where it was equipped.\n\nAnd then you have to remove deaths caused by other drivers.", "score": 1, "replies": []}]}]}, {"body": "How is testing on a private road helpful to anyone? Tesla has been able to drive fine on marked roads without traffic for almost a decade", "score": 5, "replies": [{"body": "Except for the 17 people the USA govt says died while using autopilot in a tesla.", "score": -13, "replies": [{"body": "Okay, and there are people using autopilot in their teslas while literally sleeping. You can‚Äôt fix stupid. Plus, FSD is an entirely different software stack than regular AP, regular AP is glorified cruise control. FSD has safeguards in place to prevent misuse such as sleeping while using FSD.", "score": 1, "replies": []}]}]}]}, {"body": ">That will drop >300k lines of C++ control code by ~2 orders of magnitude.\n\nWhat does this even mean? Ok it will drop over 300k lines of code but what 2 orders of magnitude is suppose to mean there? 2 order of magnitude is 10 to power of 2 so would this mean instead of 300k it is actually 30 million lines of code? Like seriously this doesn't sound like it is making sense.", "score": -6, "replies": [{"body": "300k down to 3k.\n\nHow does that not make sense?", "score": 7, "replies": [{"body": "Only having 3k lines of code doesn't sound very sensible either. But if this is true then I wonder why they went with trouble of writing 300k lines of code in the first place if they could have just done NN from the beginning with just 3k lines. Sound like a lot of wasted work.", "score": -2, "replies": [{"body": "They had neither the data, the compute nor the experience to do NN‚Äôs when they started.  And nobody else has those things today, except Tesla.", "score": 5, "replies": []}, {"body": "It's 3k for path planning specifically, but yes he might be speaking a bit hyperbolic here.\n\nIt was \"software 1.0\" as they call it, because the technology was not there yet.", "score": 6, "replies": [{"body": "I don't think he's being hyperbolic at all, neural network implementations are tiny compared to traditional logic.", "score": 2, "replies": []}]}, {"body": "Have you ever seen a neural network implementation? They're absolutely tiny compared to traditional code.  \n\n\nHere's an entire GPT implementation and the largest code files are only \\~300 lines each: [https://github.com/karpathy/nanoGPT/blob/master/model.py](https://github.com/karpathy/nanoGPT/blob/master/model.py)  \n\n\nAll of the data that powers neural networks are stored in the weights files, which are just massive data files that are generated during training.", "score": 2, "replies": [{"body": "I certainly have but usually the code is not just the neural network when you are communicating with different systems which in this case Tesla does. You have code modifying the outputs and inputs and that's why we still have NN AIs that are still potentially couple of million lines of code. You can't really just take simplest implementation out there and apply that to everything especially not in systems that Tesla has. Otherwise everyone would just have one coder write couple of hundred lines of code and call it a day.", "score": 1, "replies": [{"body": "Of course the code isn't just the neural networks, but if you think piping images or video streams from one network to another takes millions of lines of code then I don't know what to tell you. The whole focus for the last 3 years has been to get rid of the traditional 'glue' logic and replace it with a giant pipeline where camera/kinematics/map data all flow in at the beginning and control decisions flow out at the end. To think that they have millions of lines of traditional logic somehow wedged in there would go against everything they've publicly stated about their development goals.  \n\n\n>Otherwise everyone would just have one coder write couple of hundred lines of code and call it a day.\n\nWell, that's not where most of the work lies in building useful ML software. Implementing the network is nothing, it's the data curation and training where the heavy lifting lies.", "score": 1, "replies": [{"body": "Never said it is millions of lines. Just that depending on context it can potentially get there. Doesn't mean it has to. I just think presenting someones github repo is just big oversimplification.", "score": 1, "replies": [{"body": "Look, you said \"only 3k lines of code doesn't make sense\" and I'm here showing you a few thousand lines of code that *literally runs a large language model like ChatGPT.*  \n\n\nI don't know how to make it any more clear than that. Code size is \\*NOT\\* what makes a neural network good or bad, nor is it what makes a neural network simple or complex. 3k lines of code for a fully blown control system (if it's running a ML model) makes perfect sense.. I don't know why you think it doesn't.", "score": 1, "replies": []}]}]}]}]}]}]}, {"body": "Why anyone ever uses lines of code to mean anything is astounding to me.  You can forgo the use of loops and have a zillion lines of code!  It doesn‚Äôt make it anymore complex.\n\nLines of code also means literally nothing in terms of a program doing what you want.  Would you rather use the 100,000 lines of code program that does things correctly or the 1000 line program that does it wrong?  Obviously the larger program.\n\nBig ‚Äúprint out your code‚Äù vibes here", "score": -1, "replies": [{"body": "While it is not measure of good code but if you can cut code down significantly while maintaining quality then that obviously is way less maintenance and likely faster to fix bugs.", "score": 2, "replies": []}]}]}, {"body": "I thought the entire puzzle was vehicle control?", "score": 1, "replies": [{"body": "Perception was the first part.", "score": 1, "replies": []}]}, {"body": "For those who understand what he is saying can you explain in simple terms.", "score": 1, "replies": []}, {"body": "I do wonder if training is now restricted to scenarios where the driver had to take over or the car bailed (does it even do that now) , from a training Perspective every point on the GPS map that had no interventions needs no further training right?\n\nI am also surprised that they don't add a remote driver feature where an operator can intervene with a Xbox steering wheel at their desk given the cars are fairly well connected - essentially this is what the micro-mapping robotaxis are doing when your waymo car has a panic and stops right?\n\nOr are we in regulatory hell here in that full unattended driving without driver liability is not permitted until there is no requirement for intervention? Again how do waymo etc get away with no human safety drivers?", "score": 1, "replies": []}, {"body": "Elon's insistence that replacing the perfectly good c++ code for steering the wheel, toggling the blinkers, and depressing the accelerator with neural nets makes me more bearish on FSD than I was before (I am still optimistic overall).\n\nFSD bottlenecked by data+decision-making. The entire point of NN's (as opposed to classic programming) is for decision making in areas where you can't reduce your problem down to simple rules. You wouldn't replace your light switch with a neural network -- At best, it would just be a waste of compute!\n\nThis smells like snake oil to me, and I don't like it. I would prefer Tesla to be honest about being stuck at a plateau than lie like this.", "score": 1, "replies": []}]}
