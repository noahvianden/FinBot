{"title": "Are NVIDIA's AI chips still \"so good that even when the competitor’s chips are free, it’s not cheap enough,\" as Jensen Huang said in March? ", "selftext": "TL;DR: Probably yes (just my opinion)...\n\nOn Monday, July 29, Apple Research [published the scientific background of its \"Apple Foundation Model\"](https://machinelearning.apple.com/research/apple-intelligence-foundation-language-models) (AFP). According to the paper, this model (AFP-server) was trained on 8192 of Google's TPUv4 chips, and apparently no NVIDIA GPUs were used for training (although this was not explicitly disclosed). So are Google's TPUs serious competition for NVIDIA's GPUs? Let's crunch the numbers...\n\nAccording to the [Google Cloud website](https://cloud.google.com/tpu/pricing?hl=en), a TPU v4-Pod (4096 x TPUv4) costs $32,200 per hour on demand. So the compute capacity to train the AFM-server cited in the paper costs about $64,400 per hour on-demand. 8192 TPUv4s have a combined computing power of up to 2.25 ExaFLOPS\\* (8192 x 275 TeraFLOPS\\*).\n\nOne of NVIDIA's H100 SXM (up to 3958 TeraFLOPS\\*) costs about $3-$4 per hour on-demand, according to my research. So for $64,400 USD per hour, you could rent between 16,100 and 21,000 H100 SXMs with a combined computing power of 64 to 85 ExaFLOPS\\* (16,100 x 3,958 TeraFLOPS\\* = 63.72 ExaFLOPS\\*; 21,466 x 3,958 TeraFLOPS\\* = 84.97 ExaFLOPS\\*).\n\nAccording to this calculation, using clusters of NVIDIA's H100 SXM would be **28 to 37 times cheaper** than using Google's TPUs (please correct me if I am wrong). So yes, NVIDIA's chips might still be \"so good\". And I haven't done this calculation for the upcoming Blackwell generation...\n\n\\*FLOPS (floating point operations per second) is a measure of the computing power of computer chips and correlates to the performance of matrix operations such as those required for AI training.", "id": "1egijhz", "created_utc": 1722416876.0, "score": 195, "upvote_ratio": 0.92, "num_comments": 97, "comments": [{"body": "\n**User Report**| | | |\n:--|:--|:--|:--\n**Total Submissions** | 10 | **First Seen In WSB** | 1 year ago\n**Total Comments** | 98 | **Previous Best DD** | [x](https://www.reddit.com/r/wallstreetbets/comments/xyz1pg/why_not_att/) \n**Account Age** | 1 year | | \n\n[**Join WSB Discord**](http://discord.gg/wsbverse)", "score": 1, "replies": []}, {"body": "It depends on many factors.\n\nOne thing you need to consider is that different software favors different vendors. Nvidia had the intuition of investing heavily in research, they have sponsored many university labs for a decade gifting their hardware. That meant that many now important softwares have been developed and built around maximizing Nvidia's hardware and CUDA, while Nvidia software like drivers was also tested to run great on these libraries (such as NumPy or PyTorch or TensorFlow).\n\nOn top of that Nvidia's hardware is genuinely great and arguably the best in their class, especially combined with their software and optimization for customer software.\n\nThat gives Nvidia a very serious headstart and competitive advantage in ML/AI fields.\n\nThose that mean that Nvidia has a lock up on the field forever though?\n\nNo. First of all, customers that spend billions in hardware, do not like buying it at such ridiculous margins, even though they have kind of no choice now when the race is to get products on the market first. And those ridiculous margins eventually attract competition that has the financial incentives to build great hardware and software.\n\nSecond, the biggest buyers have lots of cash and knowledge to build their own accelerators. Google has their own, Apple can build their own, AWS and Microsoft can build their own.\n\nIn other words, as soon as the fight to get products in front of users and capturing market share will be fading, the fight for operating at the lowest expenses will start. And at that point you can assume that such players with such deep pockets can write their own software and drivers and even hardware (or collaborate with the like of ARM/AMD/Intel) so that instead of spending $20B they will spend a fraction of it and avoid getting gouged quarter after quarter. And, they can also build their own ML pipelines to run best on their own hardware.\n\nIn the end I believe that anybody thinking that a company with basically only one product (GPUs), as great and hot as they are now in 2024, in a very cyclic market like hardware is worth trillions, let alone among the 2/3 biggest in the world, is out of their minds imho.\n\nPeople extrapolating current trends in decade-long growths are committing the same mistakes Tesla investors did (and keep doing), not realizing that eventually good margins will fade, that there isn't an endless queue of customers with infinite money, and that competition at some point will have their own offerings.\n\nI believe that Nvidia will keep being a major player in the field for a long time, but margins at some point will start to get back to normality with increased competition from other manufacturers and big tech building their own stack.", "score": 119, "replies": [{"body": "those margins so grand am fearful there may even be some \"spite\" carried forward to next time upgrade needed. \n\n  \nthat said, am thinking \"in house\" compute centers are only for r&d (presumably chasing agi) once that's fleshed out I imagine having your own compute centre will be rare (it will be leased from a hand full of providers)\n\n  \nimo nvda needs to get into that business (I imagine they already are) and HARD/FAST.  \n\nI think it's plausible that in the future (post AI is useful) nvda will keep it's best chips / compute for itself to lease  and use  the superiority of compute as the competitive advantage.", "score": 14, "replies": []}, {"body": "I think the genius is that they’ve tied a hardware product to a software stack and they will have the network effect locking so many people into that stack for a very very long time.  \n\n I get to the same place as you logically, but I get there by thinking that there will be a level of diminishing returns. Chips can only get so cheap per flop and so the models can only get so big. Don’t know what those limits are. But in 10 years maybe we all have a chip that is 100x as powerful as the ones today in our laptop. Or they’re so cheap we can rent all the power we need for $5/month and it’s like buying extra storage for our photos. \n\nThe latest chips will still yield cost improvements, but on the order we see today with CPUs - 5-10% per year. The older chips are fine for most applications. It becomes a cost optimization analysis where alternatives are relatively close. ", "score": 10, "replies": []}, {"body": "Agree completely. I've been writing something similar for awhile and usually just getting downvoted. People coming super late to NVDA seem to think it's going to run to 6T or 12T market cap.", "score": 4, "replies": []}, {"body": "CUDA is the answer here, this is mostly where NVIDIA’s moat lies, not their chip design. Theoretically AMD can make a faster, more efficient chip but if it their ROCm software program can’t optimize as well as CUDA can AMD won’t have any sort of advantage. \n\nCouple that with the ecosystem CUDA has created and the gold standard it has become and you start to see why NVIDIA would have a really hard time losing any marketshare for the foreseeable future.", "score": 13, "replies": [{"body": "It's both really. CUDA development is very much supported by how the hardware is designed, and vice versa. Like you don't really get one without the other. I've been doing this development since before CUDA even existed and each iteration of the hardware includes changes on how to better optimize CUDA code and the programs orchestrating it.", "score": 2, "replies": []}, {"body": "> and you start to see why NVIDIA would have a really hard time losing any marketshare \n\n\nFor training. They're already losing market share for inference. Which is still a good place to be, as inference market being easier to penetrate is going to get real competitive.", "score": 1, "replies": []}]}, {"body": "How long do you think we can expect NVDA to make these margins ? General consensus seems to be two years. Do you think this is accurate ?", "score": 3, "replies": [{"body": "As long as the focus is getting most market share possible in AI-powered software.\n\nAnd considering to how many fields this applies right now (automotive, robotics, software development, chatbots, OS and software assistants like the one Apple and Microsoft are building and bundling with their product suites, creative software like video/audio/photo editing and many others) I think Nvidia is going to shit gold for many years.\n\nOn top of that you need to add the race for AGI which will make insane money for Nvidia too, because that race is going to be about anything but maximizing operating profits for a very long time.\n\nThere's also a risk in few years the consensus may shift to \"AGI is impossible\" and investors getting wary of burning money.\n\nIt's hard to say and predict how long all of this is gonna last, whether different vendors may provide breakthrough jumps in technology to have their solutions being the most efficient at specific workloads, etc.\n\nThe reason why all of this is very hard to predict and with technology shifting at very rapid pace is why I'm wary about valuations like those we're seeing now.", "score": 6, "replies": [{"body": "Thank you", "score": 2, "replies": []}]}]}, {"body": "I think the problem lies in manufacturing. TSMC is the only one right now with 3nm process that can build at that scale and they can’t even keep up with demand. \n\nJust the equipment alone to build a fab capable of building these chips is years away and then competitors have to somehow beat them at their own game while they are wayyy ahead in processes and quality control (good luck Intel) \n\nThey will be caught like you said but it might be longer than people think as they are really really far behind ", "score": 3, "replies": []}, {"body": "AI definitely wrote this", "score": 5, "replies": [{"body": "I didn't originally write this in English, but used AI to help translate, so yeah, kind of...", "score": -4, "replies": [{"body": "Confused. Are you posting from two accounts then? I was saying this response was AI", "score": 1, "replies": [{"body": "Oh sorry, I mixed this up... thought you meant my original post :D. I just have one account :-)", "score": 0, "replies": []}]}]}]}, {"body": "Thanks for the great comment! I would agree, but I think NVDIA introduced subscription (Enterprise AI) models for its GPUs at the right time. In the first phase of the AI revolution, Big Tech bought the chips, now other industries will follow, but they will choose a subscription model from NVIDIA. This could generate sustainable revenue for years to come.", "score": 8, "replies": [{"body": "Big tech will never commit hundreds of billions in getting vendor locked. They will instead commit into minimizing operational costs. When margins are as high as they are now, there's too many incentives to build alternatives.", "score": 13, "replies": [{"body": ">Big tech will never commit hundreds of billions in getting vendor locked.\n\nI mean...many have with Cisco over the years on the networking side lol. Not as pricey hardware in some cases and margins aren't as high, but the behavior is definitely there.", "score": 5, "replies": [{"body": "You actually made an example that backfires:\n\nAWS, the biggest cloud vendor on the planet, has indeed built their own custom routers on top of the Broadcom Tomahawk ASIC further solidifying my thesis: at those scales you implement custom solutions and avoid as much as possible external vendor locking.\n\nThe second biggest cloud (Azure), uses Nokia-derived custom routers and switches and Arista ones.\n\nI bet they also buy from Cisco, but all those big companies build a software stack around white boxes, where they can leverage their position to get the best pricing and not be vendor locked.\n\nGoogle has always kept their hardware infrastructure secret, but it's a well known fact that since a decade or more it is entirely software defined and uses their own built hardware.\n\nAt the scale big tech operates, you don't get vendor locked or you build your own hardware.\n\nThe same will happen with GPUs when the focus will switch from being first to market. Now they want to capture market share and don't look at the bill, Nvidia makes gargantuan amounts of money. But this will change with time. It's unavoidable.", "score": 10, "replies": [{"body": "The hyperscalers are only ~5-10% of the OEM IT hardware marketshare, with the vast majority still being enterprise data centers and smaller data center rooms and closets who are using OEM products (and sadly mostly Cisco). The OEM chunk of the market is still over 50% of overall sales.", "score": 3, "replies": [{"body": "> The hyperscalers are only ~5-10% of the OEM IT hardware marketshare\n\nBig tech makes up 40% or more of NVDAs revenue. Them and big VC backed AI startups are the only ones who can afford GPUs.\n\nhttps://www.nasdaq.com/articles/who-are-nvidias-largest-customers#:~:text=Unsurprisingly%2C%20big%20tech%20companies%20like,are%20significant%20customers%20of%20Nvidia.", "score": 3, "replies": [{"body": "I was referring to OEM systems like servers and network equipment tied to my Cisco example, not accelerator cards that the big cloud providers are gobbling up at the moment.", "score": 1, "replies": []}]}]}]}]}, {"body": "i know we buy those chips by the billion...", "score": 2, "replies": []}, {"body": "> Big tech will never commit hundreds of billions in getting vendor locked.\n\nThey will and do, it is not unusual in the industry.", "score": 0, "replies": [{"body": "Show me a single cloud vendor among the biggest ones (Google, Amazon, Microsoft) that is locked in on a single hardware vendor. You can choose anything from routers, to switches to CPUs.", "score": 1, "replies": [{"body": "Hyperscale customers making their own, everyone else negotiating discounts", "score": 0, "replies": []}]}]}]}]}, {"body": "I agreed with the assessment but if having a lot of money will create meaningful competition then why in the mobile/server OS domain, there is still no raising 3rd OS?", "score": 2, "replies": [{"body": "Because there's no economic incentive nor technical reason to do so. Android and Linux (on which Android is based) are open source and free projects. MacOS and iOS too are unix-derived. The operating system in the PlayStation is also unix-derived (albeit on BSD).\n\nTechnically speaking, Windows is also available on ARM CPUs so deriving a mobile version (which they did in Lumia times) is an option, albeit pointless because they don't sell such hardware.\n\nIt's more efficient for all those big tech giants to contribute to each other's projects (like Microsoft does with Chrome on which Edge is based) than maintain their own browser (like they did with older Edge and Internet Explorer). It's a win/win for everyone. Google gets lots of contributions from other companies for free and Microsoft saves a lot of effort/money.\n\nIf Android was a closed-source project, you would see more OSs.", "score": 4, "replies": []}, {"body": "There's a lot of competition, but it's built on the open projects that won out.\n\nOn the server side linux (and other free unixs). The biggest contributors to linux are the big tech companies. They all have public (and I'm sure private) versions.\n\nMobile is a little different because the OS is so tied to the hardware, but Android (AOSP) won in the sense that it's open and anyone can use it.", "score": 1, "replies": []}]}, {"body": " Apple charges 30% just to be on the Apple Store, that's just the right to play there, no real product. I don't think most people realize high margins are typical in the tech space.", "score": 2, "replies": []}, {"body": "Holy shit. It's Chad Dickens.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/wallstreetbets) if you have any questions or concerns.*", "score": 4, "replies": []}, {"body": "numpy does not use GPUs", "score": 1, "replies": []}, {"body": "Two things to add: NVDA trades at over 30 P/S. I’ve NEVER heard of a company this size category trading at that. It implies massive sustained growth expectations at a never before seen scale. Inference on AI is also substantially cheaper than model training. The next generation of models already have their hardware set for training most likely. That means NVDA is about to lap some very very tough comps and won’t be able to guide to high growth in the next quarter or two. By that, I mean that 30% YoY realized growth will be meaningless unless they can guide to 30% next year also, and hand wave line of sight beyond that even. If they can’t hand wave that to the street then that P/S falls like a rock and they can get cut in half overnight. Because 15 P/S is STILL expensive for a company that would be worth over a trillion.", "score": 1, "replies": []}, {"body": "I think AMD is a good example with their recent GPU. I honestly can see NVDA having really strong competition in less than 1/2 a decade", "score": 1, "replies": []}]}, {"body": "[deleted]", "score": 28, "replies": [{"body": "Don't you think it's strange that the details of which chips were used went viral immediately (2 small paragraphs in a 47 page paper)? Normally, Wall Street is not very interested in Big Tech's scientific publications.\n\nIt's also no secret that NVIDIA is not very popular in Apple's inner circle. \n\nA plunge in NVIDA's stock price like yesterday can free up hundreds of billions of dollars that need to be reinvested... and tomorrow is Apple's earnings report...", "score": 17, "replies": [{"body": "Apple is already a massive Google Cloud customer, so they already have the commercials/network/etc ready to go, which is easier than doing it themselves given Google had the capacity already installed and available. And given the size of their spend I'm sure Apple would get special pricing and access to engineering in return for telling the world it's done on TPU's.\n\n8 exabytes of Google Cloud Storage to power iCloud, and that was 3 years ago so it's probably grown heaps since then... https://www.theinformation.com/articles/apples-spending-on-google-cloud-storage-on-track-to-soar-50-this-year", "score": 9, "replies": []}, {"body": "[deleted]", "score": 14, "replies": [{"body": "It’s not a conspiracy at all, them smart-arse moneys want you to dump the stock so that they can accumulate before it shoots to the new ATH after earnings ![img](emote|t5_2th52|4271)", "score": 14, "replies": [{"body": "exactly", "score": 1, "replies": []}]}, {"body": "So the assumption that two of the largest competing tech companies would do things to hurt their competitors is a conspiracy theory?", "score": 5, "replies": [{"body": "that is literally what a conspiracy is", "score": 4, "replies": [{"body": "TBF that words meaning has been getting used differently nowadays", "score": 2, "replies": []}]}]}]}, {"body": "I also find it funny that Apple announced their AI was delayed then it’s been widely popular (all of a sudden even though it’s kind of old news) that they weren’t using NVDIA chips. Just adding a funny coincidence I noticed. \n\nhttps://www.reuters.com/technology/apples-artificial-intelligence-features-be-delayed-bloomberg-news-reports-2024-07-28/", "score": 3, "replies": []}, {"body": "> normally Wall Street is not very interested in Big Tech’s scientific publications. \n\nWell that’s just flat out false. I’m guessing you’ve never worked on, or even talked to, anyone on Wall Street. Buyside and sell side tech analysts have been closely tracking AI research since chat-GPT blew up in late 2022. Meta’s research paper in March drove upside in ANET stock and papers on liquid cooling have been hugely beneficial to VRT.", "score": 2, "replies": []}]}]}, {"body": "A TPU is an ASIC so very specialized for some jobs while a GPU is more generalized. A matchup on gross TerraFLOPS may not be apples to apples for the particular training Apple was running.", "score": 5, "replies": []}, {"body": "Google Cloud pricing vs \"according to my research\" ...\n\nThen you arrive at an order of magnitude difference in price. Putting aside considerations like chip availability and attempts to avoid vendor lock-in, wouldn't that result give you a pause ? Make you rethink your research ?\n\nApologies for being sarcastic but I've seen so many regards being so confidently wrong about technology that I'd have to see that research of yours before I even consider your opinion.", "score": 19, "replies": [{"body": "It was not that easy to research the prices for H100 on demand, if you have better sources/numbers feel free to share them here. But for the point I wanted to make, it doesn't really matter if the cost is 20, 30, or 40 times lower. The point was that NVIDIA's chips are an order of magnitude more cost efficient.", "score": 5, "replies": [{"body": "Quite easy, just go to the AI gpu aggregator companies, like NebiusAI, Fluidstack or Nexgen cloud.", "score": -1, "replies": []}]}]}, {"body": "was super happy to see AMD making money with AI chips. \n\nI suspect the bump to nvda was due to that likely easing anti-trust pressure / concerns.", "score": 4, "replies": []}, {"body": "Far from truth. New generation ASICs way faster than even Nvidia's next generation Blackwell GPUs plus more energy efficient.\n\n[https://entechonline.com/sohu-vs-nvidia-ai-chip-a-scientific-comparison-of-speed-and-efficiency/](https://entechonline.com/sohu-vs-nvidia-ai-chip-a-scientific-comparison-of-speed-and-efficiency/)", "score": 13, "replies": [{"body": "I don't think ASICs can be used for training right now. But yes, ASICs may be the next big thing in AI.", "score": 16, "replies": [{"body": "\"Application-Specific Integrated Circuits\" designed for training are, in fact, very usable for training. \n\n\nAs it happens, Tesla's Dojo chip is in fact an ASIC built for training, and tesla is far from the only ones going in that direction", "score": 1, "replies": []}]}, {"body": "Is this still only for inference or can training also be done?", "score": 8, "replies": [{"body": "You still need GPUs for training according to some articles. Im no expert tho", "score": 3, "replies": []}]}, {"body": "asics are highly specialized: these are only good at inference in short context lengths, and cant be used to train GPUs either. considering the level of development and innovation happening with ai models they won't be competition just yet\n\nthis comment has more info: https://www.reddit.com/r/LocalLLaMA/comments/1dq8o02/comment/lantcbl/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button", "score": 12, "replies": []}, {"body": "The article says it outperforms H100 and not Blackwell", "score": 4, "replies": [{"body": "The information I provided was not based on this specific articles. If you care to search on google you would find related information in 10 seconds.\n\n[https://www.all-about-industries.com/asics-versus-gpus-does-the-ai-future-not-lie-in-nvidias-hands-a-616108ac6928e3d542c757192c7c26e7/](https://www.all-about-industries.com/asics-versus-gpus-does-the-ai-future-not-lie-in-nvidias-hands-a-616108ac6928e3d542c757192c7c26e7/)", "score": -3, "replies": []}]}]}, {"body": "Short answer - yea", "score": 2, "replies": [{"body": "nothing to add here :-)", "score": 0, "replies": []}]}, {"body": "the industry has all been software optimized towards Nvidia,, and even better hardware wouldn't shake Nvidia.", "score": 2, "replies": [{"body": "Indeed, CUDA is a moat per excellence...", "score": -1, "replies": []}]}, {"body": "[deleted]", "score": 1, "replies": [{"body": "This does not change the ratios, as this applies to both chips…", "score": 2, "replies": []}]}, {"body": "There's an interconnect difference on the TPUv4 torus that scales differently, perhaps Apple's model needs that many chips to fit it all in HBM.", "score": 1, "replies": []}, {"body": "How big of a difference is Blackwell's?", "score": 1, "replies": []}, {"body": "if you've been paying attention there's a new chip right over the horizon that will render nvidia to the way of x86", "score": 1, "replies": []}, {"body": "Interesting \n\n(It is an apples to oranges comparison, as they process information differently.), the Human Brain processing power has been estimated at 1 exaflops, \n\nEnergy-wise, the Human Brain consumes 20 watt-hours to ‘produce’ an exaflop, \n\nFrontier needs 20 million watt-hours!\nJan 10, 2024", "score": 1, "replies": [{"body": "But if you buy apples and oranges just for the calories the comparison works just fine ;-)", "score": 3, "replies": []}]}, {"body": "There was an article just a couple of days ago on CNBC discussing AAPL using GOOG chips. Near the end of the article,\"\n\n\"Still, Google is one of Nvidia’s top customers. It uses Nvidia’s GPUs its own *\\[sic\\]* TPUs for training AI systems, and also sells access to Nvidia’s technology on its cloud.\"", "score": 1, "replies": []}, {"body": "Im just making this comment because I’ve noticed a really interesting potential correlation and what for I’m still at a loss for. Every Wednesday, Oil Inventories comes out and every time they come out NVDA pumps. This has happened cleanly since January when the market (ie NVDA really took off) and I can’t figure out what the fuck it is.", "score": 1, "replies": []}, {"body": "You have to look at the broader implementation of hardware. Is there competition across the board of nvidias products? Yes. Is that competition beating nvidia in the top spot for years on end? As far as I’ve seen no. Nvidia generally is the top hardware or near the top in terms of performance. Even if they’re behind this year I don’t worry about them being ahead in a few months is the train of thought and that matters when you’re scaling a business. It matters in hardware especially because the investment for businesses is twofold in both hardware and software that leverages specific hardware. To change hardware would require changing software so basically any change is now a x2 or more cost. Therefore, businesses stick with the most consistent winner and that happens to be nvidia for the time being.", "score": 1, "replies": []}, {"body": "They're buying AMD chips, imagine how desperate companies are to buy Data Center chips.", "score": 1, "replies": []}, {"body": "NVDA AI stack is the moat, not the chip. It's impossible to find tune AI quickly without Pytorch, which apparently needs CUDA for speed, which needs the latest NVDA card. Nobody is going to rewrite Pytorch library without some investments. I mean I will if someone here wants to pay me $200K for the year of work.", "score": 1, "replies": []}, {"body": "CUDA !!!!!!", "score": 1, "replies": []}, {"body": "Half the power consumption- infrastructures biggest bottleneck is power consumption.", "score": 1, "replies": []}, {"body": "Coral. its 30 bucks. no one uses it currently. Jensen is never wrong", "score": 1, "replies": []}, {"body": "TSMC will never let Nvidia fail. That’s going to be their bread and butter", "score": 1, "replies": []}, {"body": "Thank you all so much for reading my post! You motivated me to do a more detailed calculation (including an estimate for Blackwell) and I just wrote a block post about it. You can find it here: https://www.chaotropy.com/why-googles-tpus-are-no-match-for-nvidias-gpus/", "score": 1, "replies": []}, {"body": "the problem with Google is that they stop at the bare minimum. They don't want to push the boundaries because their OKR planning involves unnecessary prioritization exercises rather than imagining the future. There is noone willing to bet their ass off for shaping the future beyond a year or so. Engineers don't even think beyond a quarter. As opposed to Nvidia. They are lean and not much layered BS and have one visionary who is willing to imagine and build for beyond 5 years in the future. Competition will always play catch-up with Nvidia. Their blackwell is going to be way cheaper and energy efficient than previous generations and everyone is just drooling and waiting to get their hands on it. Just buy any dips around 100s and wait for 150 for the next earnings.\n\n\nThe real AI isn't what we see today, but it's coming and it is going to need massive massive training capabilities. But if this compute isn't available to researchers, there won't be any major breakthroughs. Only Nvidia will cater to these researchers and make sure they are ready for the next leg up.", "score": 1, "replies": []}, {"body": "There will always be a market for premium products, and a market for more affordable options.", "score": 1, "replies": []}, {"body": "There is no AI chip, these chips are made for machine learning and LLMs, not AI.", "score": 0, "replies": [{"body": "Okay, and LLMs are not AI? :-D", "score": -2, "replies": [{"body": "No, there is no intelligence envolved, it just gives you the most average result from the database, it doesnt know what it is doing, or what it is generating. \n\nWe wont have any sort of AI, real AI in the next 10 years at least.\n\nMachine/Algorithmic Learning is NOT AI.", "score": -7, "replies": [{"body": "This is becoming the new ackshually", "score": 2, "replies": [{"body": "Its just the truth, ask anyone who works with it. Not saying there isnt value, there is, but its not AI in any way shape or form.", "score": -1, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "I work with LLMs.\n\nbut ok, go ahead son.", "score": 0, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "If AI is an EV, then LLMs are the first dirt roads.\n\nDo you call a dirt road a car?", "score": 1, "replies": []}]}]}]}]}]}, {"body": "Of course this is AI, we are simply in the infant stages. Trying to throw guardrails around the definitions doesn't make it go away. And \"the most average result\" is really minimizing what's going on, there are a few different paths to how current generative models produce a result (nearest neighbor, regressive, etc). Are you really going to suggest a neural network based model is simply returning \"the average\" result?", "score": 1, "replies": []}, {"body": "The result is AI. Machine learning is the process to create the models which then is AI.", "score": 1, "replies": []}, {"body": "Cool, thanks for the comment…", "score": 0, "replies": []}]}]}]}, {"body": "stop taking about NVDA, it will up and up.", "score": 0, "replies": []}, {"body": "No.", "score": 0, "replies": []}, {"body": "Until someone comes out with something better", "score": 0, "replies": []}, {"body": "such a small difference; the cost should be several magnitude higher.  absolutely unacceptable!\n\nfire the management team and dissolve the board immediately.  /s", "score": -1, "replies": []}]}
{"title": "Buy high sell low", "selftext": "-10 000 realized loss the day before an historic +15% on NVDA. And I held those calls for weeks...\n\nThese contracts are now worth double.. ", "id": "1egzswj", "created_utc": 1722463340.0, "score": 275, "upvote_ratio": 0.98, "num_comments": 97, "comments": [{"body": "\n**User Report**| | | |\n:--|:--|:--|:--\n**Total Submissions** | 4 | **First Seen In WSB** | 3 years ago\n**Total Comments** | 293 | **Previous Best DD** | \n**Account Age** | 4 years | | \n\n[**Join WSB Discord**](http://discord.gg/wsbverse)", "score": 1, "replies": []}, {"body": "this is the way", "score": 113, "replies": [{"body": "OP with the classic paper hands", "score": 33, "replies": [{"body": "No it seems here like he somehow managed to turn his diamond hand into paper on the perfect day to sell low, he has perfected the wsb way.🙌🏽😎see u at Wendy’s soon buddy🫡", "score": 20, "replies": []}]}]}, {"body": "https://preview.redd.it/v07ofz5w4yfd1.jpeg?width=500&format=pjpg&auto=webp&s=4ebbb203d482e30d9752082e51ba3eaff9d05fc6", "score": 113, "replies": []}, {"body": "Well, this is definitely worth some revenge trade! Ride the wave my brother, it has just started", "score": 42, "replies": [{"body": "I thought what I have felt in my belly was better traders fucking me... But yeah maybe it is just revenge.", "score": 1, "replies": []}]}, {"body": "Thanks for selling bro I got NVDA 120c before close and now it already ITM ![img](emote|t5_2th52|4271)", "score": 25, "replies": []}, {"body": "Or as I like to do it:\n\nhttps://preview.redd.it/pe90x1729yfd1.jpeg?width=1290&format=pjpg&auto=webp&s=a43cee99b4c4c2ff890f930402e661f550956faa\n\nGo all in and then sell at the bottom before a 100k gain!", "score": 24, "replies": [{"body": "You sold all 92 contracts at a loss?", "score": 8, "replies": [{"body": "Yup tried to buy the rebound saw it dipping back down and hit sell. Thought I was cutting my losses. But I just cut my gains 😎", "score": 7, "replies": [{"body": "These were fine to cut losses, but OP had until Sept 2024 and still paper handed.", "score": 7, "replies": [{"body": "Lol meanwhile I bought my 136C at around $130 range in June, still down $10,000 but they expire Nov 20", "score": 3, "replies": [{"body": "honestly, this might be in the money by then!  NVDA should blowout earnings!", "score": 1, "replies": []}, {"body": "Have you been selling weekly $136 calls?", "score": 1, "replies": []}]}]}]}]}, {"body": "Bro do tell, because this hurts my soul… not to know how it turns out.. (fill in whatever cute emoji we have for this one).. even if it was just added today to your watchlist, gain/loss porn to watch in any way is fun to know for predictions alone, and I’ve seen many with real and fake money, both fuel my gambling addiction…", "score": 3, "replies": [{"body": "Can’t add more than 1 contract to a watchlist as far as I know\n\nhttps://preview.redd.it/gvtqq9ic1zfd1.jpeg?width=1290&format=pjpg&auto=webp&s=7146b9925fb28104378d00e4ee8e084d05112616\n\nBut here is the history of me going all in these weeklies", "score": 1, "replies": []}]}, {"body": "I was shitty because I could not triple down on Tuesday.  Due to getting a margin call.  Now I only feel half as bad.  Thanks ![img](emote|t5_2th52|4271)", "score": 1, "replies": []}]}, {"body": "That sucks. No one saw %15 jump coming .. that's a huge pop", "score": 19, "replies": [{"body": "No one saw a 17% jump lol", "score": 12, "replies": [{"body": "Was it 17 ?  Damn.  Maybe MY  12/16/26 $112's will still get me paid  I think my break even is $153. ...Only 28 months til expiration YOLO!!!", "score": 3, "replies": []}]}]}, {"body": "Buy high, see green, hold, sell low.", "score": 14, "replies": [{"body": "![img](emote|t5_2th52|27189)", "score": 3, "replies": []}]}, {"body": "ALL HAIL PAPER HANDS!", "score": 11, "replies": []}, {"body": "HAHAHA FUCK", "score": 17, "replies": []}, {"body": "jesus christ![img](emote|t5_2th52|31225)", "score": 7, "replies": []}, {"body": "Hindsight is 20/20.  \nEasy for everyone to come down on you now AFTER the fact.   \nBut the truth is many people have been panic selling for a few days.   \nHope you make that money back in some other way.", "score": 8, "replies": []}, {"body": "They don’t call it diamond hands for nuthin", "score": 6, "replies": []}, {"body": "you listened to all the morons. I'm sorry, friend.", "score": 6, "replies": []}, {"body": "Youll get em next time 👍", "score": 5, "replies": []}, {"body": "![img](emote|t5_2th52|31225)![img](emote|t5_2th52|4271)", "score": 3, "replies": []}, {"body": "You can always buy them back. It’s not like these contracts don’t exist anymore!", "score": 3, "replies": [{"body": "At an even higher price and then panic sell again as it drops.", "score": 6, "replies": [{"body": "Classic move of a true wsb regard ![img](emote|t5_2th52|4271)![img](emote|t5_2th52|4267)", "score": 4, "replies": []}]}]}, {"body": "Why you did that?", "score": 2, "replies": []}, {"body": "![img](emote|t5_2th52|52627)![img](emote|t5_2th52|52627)![img](emote|t5_2th52|52627)", "score": 2, "replies": [{"body": "This guy", "score": 2, "replies": []}]}, {"body": "I had AAPL 200c 6/20 on my watchlist in early May- didn't fully trust that it would hit but wanted to keep an eye on it. Would have been a 20x play. Just learn to remember and trust your thesis- if it was good enough to put money behind, it's good enough to be uncomfortable for. Best of luck", "score": 1, "replies": [{"body": "Nope. Your conclusion is a big bias mistake. You only remember that thought because you were reminded of it when Apple shot up. Meanwhile you had 20 other thoughts you also didn’t follow but which also didn’t catch your attention after because they didn’t move accordingly. \n\nSo no, don’t „just go with your thesis“. \n\nI mean please do, I’ll enjoy the loss porn.", "score": 6, "replies": [{"body": "The thesis was that apple was undervalued for being the richest country's favorite consumer tech company for the past decade but I was not liquid when it was 0.99 a call", "score": 1, "replies": [{"body": "The bias is an important thing to watch out for though. Gambling is not a science or an art", "score": 1, "replies": []}]}]}, {"body": "Most people’s thesis is “stonks go up right?”", "score": 1, "replies": []}]}, {"body": "I sold my nke calls today I waited a month for it to rebound a little but no luck now it will go over 80 next week.", "score": 1, "replies": []}, {"body": "Good stop loss though", "score": 1, "replies": []}, {"body": "Ouch brudda", "score": 1, "replies": []}, {"body": "Here you go ![img](emote|t5_2th52|4267)![img](emote|t5_2th52|4271)", "score": 1, "replies": []}, {"body": "Damn", "score": 1, "replies": []}, {"body": "this one hurts", "score": 1, "replies": []}, {"body": "So short it now to recoup some losses 🤷 😅\n\nOr just short crypto, it wants to crash so hard... 🤷", "score": 1, "replies": [{"body": "how about u eat my ASS\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/wallstreetbets) if you have any questions or concerns.*", "score": 0, "replies": []}]}, {"body": "Big yikes ![img](emote|t5_2th52|27421)", "score": 1, "replies": []}, {"body": "that is fuckin painful", "score": 1, "replies": []}, {"body": "U fokken donkey!’", "score": 1, "replies": []}, {"body": "Lol, you are now future Wendy’s employee of the month!", "score": 1, "replies": []}, {"body": "You must be new", "score": 1, "replies": []}, {"body": "same happened to me, but i only realized a $1000 loss. bought puts yesterday morning only for it to reverse and i realized another $2000 loss. hoping to ride the wave tomorrow and make it all back with 1DTE calls.", "score": 1, "replies": []}, {"body": "Now 17%", "score": 1, "replies": []}, {"body": "this is hurting my brain", "score": 1, "replies": []}, {"body": "Why did you even sell these????? You could've sold some calls to make it a calendar spread with that much time.", "score": 1, "replies": []}, {"body": "HAHAHAHAHAH. but sorry that has to hurt bigggy.  ![img](emote|t5_2th52|4260)", "score": 1, "replies": []}, {"body": "Thats what you get for beeing a paper handed bitch.\nWhen you buy options, it's either sell at a profit or ride em till Valhalla.", "score": 1, "replies": [{"body": "But there's nothing a 0DTE yolo cannot fix.\nYou got this", "score": 1, "replies": []}]}, {"body": "Noooo", "score": 1, "replies": []}, {"body": "Thank you for your sacrifice", "score": 1, "replies": []}, {"body": "i thought i was the only one who missed the boat", "score": 1, "replies": []}, {"body": "Why sell that day with sept expiration date?", "score": 1, "replies": []}, {"body": "I diamond handed!!", "score": 1, "replies": []}, {"body": "It's okay I sold my contracts for a 100% gain when it could've been a 300% gain.", "score": 1, "replies": []}, {"body": "Your contracts were for September, tho.![img](emote|t5_2th52|4271)", "score": 1, "replies": []}, {"body": "This is the definition of paper hands ![img](emote|t5_2th52|4271)", "score": 1, "replies": []}, {"body": "Bro! Your calls don’t expired in like 2 months![img](emote|t5_2th52|4271).  You can still buy in tomorrow because this rocket is going back to 140 and beyond![img](emote|t5_2th52|18630)", "score": 1, "replies": []}, {"body": "Ooof ![img](emote|t5_2th52|31225)", "score": 1, "replies": []}, {"body": "I'm still holding my 128 calls for the same expiry and my cost is 15.75 ![img](emote|t5_2th52|4267)", "score": 1, "replies": []}, {"body": "And I was feeling bad about selling my 114 c for a loss of 145..", "score": 1, "replies": []}, {"body": "🧻✋", "score": 1, "replies": []}, {"body": "fuck", "score": 1, "replies": []}, {"body": "These would print big if waited until expiration.", "score": 1, "replies": []}, {"body": "bruh you had months on expiration", "score": 1, "replies": []}, {"body": "I know your pain, been there done than repeatedly.", "score": 1, "replies": []}, {"body": "selling the shovel company in a gold rush", "score": 1, "replies": [{"body": "My worst trade since the covid crash", "score": 1, "replies": []}]}, {"body": "Timed it perfectly ", "score": 1, "replies": []}, {"body": "my condolences bro", "score": 1, "replies": []}, {"body": "its not the MONEY you should worry about, drop 60k then we emotion u", "score": 1, "replies": []}, {"body": "Thats my drilla 😁😁👍", "score": 1, "replies": []}, {"body": "And what is the risk that these contracts get exercised now if the person you sold to is holding?  If NVDIA goes way up before Sept....", "score": 1, "replies": []}, {"body": "You feel better after today?", "score": 1, "replies": []}, {"body": "Welcome to the future. It is now at $130.", "score": 1, "replies": []}]}
