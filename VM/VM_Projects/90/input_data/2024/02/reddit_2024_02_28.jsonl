{"title": "Morgan Stanley's Adam Jonas on Apple canceling their EV (too few cars to collect meaningful amounts of data)", "selftext": "[ Removed by Reddit in response to a copyright notice. ]", "id": "1b2arpz", "created_utc": 1709138997.0, "score": 66, "upvote_ratio": 0.92, "num_comments": 95, "comments": [{"body": "\"Tesla's vehicle fleet drives around 100 thousand miles per minute. Tesla's fleet drives more miles in 5 minutes than Apple's fleet reportedly drives in a year\"", "score": 38, "replies": [{"body": "Was there way to measure how much of those data contribute to meaningful training and improvement?", "score": 2, "replies": [{"body": "None that we have access to. But even if you need 1000 miles of Tesla driving data to be as good as 1 mile of Apple's, Tesla is still two orders of magnitude ahead of Apple.", "score": 2, "replies": []}]}, {"body": "I always wonder how different the news would take FSD if it had just started being developed with v12. Now that there’s been many other people who failed.  Like how much of an advantage does Tesla have from starting so early or did all that really help the code rewrite from scratch etc", "score": 2, "replies": []}, {"body": "And Tesla collects small snippets of low res webcam data, with no ranging information. How are those numbers in any way comparable?", "score": -19, "replies": [{"body": "What is even your point?", "score": 10, "replies": [{"body": "The point seems quite clear? Parent is saying the two numbers are not comparable — low-fidelity data is not equivalent to high-fidelity data.", "score": 1, "replies": [{"body": "What makes Apples data \"high fidelity\"?", "score": 9, "replies": [{"body": "Based on [what we've seen](https://thelastdriverlicenseholder.com/category/apple/), Apple was using a full multi-modal stack using vidar, lidar, radar, uss, and probably more. Of course, we have no insiders willing to comment/confirm, but it's almost certain all of that was being stored locally at full-res and brought into their data engine.", "score": 0, "replies": [{"body": "Ok and based on Tesla validation, [they have also been using the same suite of lidar sensors](https://thelastdriverlicenseholder.com/2022/02/22/tesla-model-3-spotted-with-lidar-rack/) to test and validate data... Where are we going with this?", "score": 5, "replies": [{"body": "I'm not sure where you're going with this. If your argument is that Tesla only has a very small fleet of cars doing high-fidelity data gathering operations (and with what appears to be a much more simplified rig) then you agree with the other commenter.", "score": -4, "replies": [{"body": "No I'm saying based on the comment I posted under, I don't get what their point is. The data Apple has, Tesla has already and better and more and has a robust network to collect or distribute to in virtually real time once Dojo is operational. What makes Tesla's current situation less than Apples? They are compatible since Tesla has done the same leg work Apple is now doing, they have elements beyond what Apple has now.", "score": 7, "replies": [{"body": ">No I'm saying base son the comment I posted under, I don't get what their point is. \n\nThey already explained their point. I've now re-explained it to you in detail. Asking me to do it again a third time is just willful ignorance and sealioning at this point. High-fidelity data is not equivalent to low-fidelity data.", "score": -1, "replies": [{"body": "Willful ignorance of what? The fact that they are calling Tesla's position ahead of Apple incomparable is laughable.", "score": 0, "replies": [{"body": "You've already agreed that's the case: High-fidelity data is not equivalent to low-fidelity data. You noted yourself that Tesla runs a small fleet of high-fidelity vehicles, for this very reason.", "score": 2, "replies": [{"body": "No I said they have the same thing that Apple has and more, whatever Apple is collecting, Tesla has already, so they've already met apples to apples. The cherry on top is that Tesla has a large fleet collecting data that Apple can't get near and would need to achieve what Tesla is achieving. So to say they aren't comparible when Apple is X and Tesla is X² is ridiculous.", "score": 0, "replies": [{"body": "If Tesla has a high-fidelity fleet, then those high-fidelity miles must be more valuable than the low-fidelity miles. Therefore, low-fidelity and high-fidelity miles should not be directly compared. Instead, you would compare low-fidelity miles to low-fidelity miles, and high-fidelity miles to high-fidelity miles as a separate figure. \n\nYou might then say Tesla does some off hundred thousand number of high-fidelity miles per year, and that Apple was doing some other odd hundred thousand high-fidelity miles per year, and that *additionally,* Tesla does some odd billion or so low-fidelity miles per year. \n\nUp to you, then how you weight the value of low-fidelity miles and high-fidelity miles, and how much you weight the fidelity of the miles themselves. But what's clear, as per Tesla's own need for a high-fidelity fleet deployment, is is that a low-fidelity mile is not equivalent to a high-fidelity mile. \n\nHope that helps.", "score": 1, "replies": [{"body": ">a low-fidelity mile is not equivalent to a high-fidelity mile. \n\nMy point is that Tesla has both, they have what Apple has (high-fidelity miles) and what Apple would hope to attain (low-fidelity miles), so to say they aren't comparible is insane.", "score": 0, "replies": [{"body": ">My point is that Tesla has both\n\nWhich is completely tangential to the point at hand, other than to once again underscore that the two are different, unalike-for-unalike things. *Your own statement right now* confirms that.", "score": 1, "replies": [{"body": "Not it's not it's to the point. Here's the original comment I'm responding to\n\n>And Tesla collects small snippets of low res webcam data, with no ranging information. How are those numbers in any way comparable?\n\nTheir point of saying it's incomparable falls when you factor that Tesla has collected the same style of data already. Apple is at the foot of the mountain.", "score": 1, "replies": [{"body": "Again, you've just confirmed the \"hundred thousand miles per minute\" data is not the same style of data. It is low-fidelity data. Tesla collects high-fidelity data, but at a lower rate, on a smaller fleet — some likely hundred-thousand odd miles per *year*.", "score": 1, "replies": [{"body": "Who told you it's slower rate or smaller fleet?? Tesla has millions of cars they have the ability to strap the same amount of cars and collect the same amount of high-fidelity data, and likely have. Again your grasping at straws at this point.", "score": 1, "replies": [{"body": ">Who told you it's slower rate or smaller fleet??\n\nYou did, just a moment ago. You linked me to a picture of one of Tesla's small-fleet multi-modal test/validation cars, which we can both agree has a different sensor arrangement from the consumer vehicles, more akin to what Apple was using.", "score": 1, "replies": [{"body": "I never said that, please quote me if ever I did.\n\nI've said Tesla has the same data Apple has and more so where are you pulling that from?", "score": 1, "replies": []}]}]}]}]}]}, {"body": "But the comparison OP and Jonas are making is only to the low fidelity data, which they claim is advantageous due to quantity, but ignores the fact that the quality makes it far less suitable for training. If the response is Tesla also has some high fidelity data, then what’s the point of the data quantity argument?", "score": 1, "replies": [{"body": "But low fidelity data is what AI and NNs train on, real world data at scale is often low-fidelity. It's not advantageous as it takes too long to process in most cases and you can source enough of it to matter especially at scale. Often most methods reduce \"high-fidelity\" data down to low-fidelity state before processing.", "score": 0, "replies": [{"body": "No, it’s not. You don’t train neural networks from just random crappy data. You need data that’s representative of the target distribution. More importantly, you need something to compute gradients against. That’s a problem when you’re dealing with just grainy webcam images.", "score": 1, "replies": [{"body": ">random crappy data\n\nI love how you adlib here\n\n>More importantly, you need something to compute gradients against. That’s a problem when you’re dealing with just grainy webcam images.\n\nYou are working with a limited compute window and low bandwidth for near realtime response nothing on the market is capable of that at scale other than what Tesla has put forth. You saying what they need when they have proved otherwise is trying to fit a square in a circle. \n\nApple clearly realized this and gave up. Again the data that Apple is collecting is data that Tesla has and they have determined that the need is ok the \"low-fidelity\" side for at scale deployment.", "score": 1, "replies": [{"body": "Are you saying we need a solution that avoids gradient computation to fit within a certain response time?", "score": 1, "replies": [{"body": "That's a huge assumption that Tesla doesn't use gradient computation, make me feel like you don't truly know what that is or how it applies. From what I have seen in old conference videos they actually do, idk what they use now with the end to end NN of FSDb v12 but again Tesla has the ONLY working method at scale. So whatever they are doing is what I'm saying is the requirement unless something better comes along.", "score": 0, "replies": [{"body": "That’s not what I’m saying. Of course they use gradients. My point is you’re confusing training and inference, and that you can’t just toss data from any distribution and expect the result to figure itself out.", "score": 1, "replies": [{"body": "But I never said such a thing, please point me to where you got that from. All in all Tesla has that part figured out, what I'm saying is the data Apple was collecting is data Tesla already has as they have been using the same set of sensor suites. The data Apple doesn't have is the real world fleet data that Tesla does have, making Tesla at least Apple++ if not Apple². The point I was wholly making is that is ludicrous to think that there no base for comparison.", "score": 1, "replies": [{"body": "> You are working with a limited compute window and low bandwidth for near realtime response\n\nThat only applies to inference, not training. You seem to not understand the difference between the two.\n\n> All in all Tesla has that part figured out\n\nAh yes, just declare the issue of actually computing a loss function doesn't apply to Tesla, because, sure, whatever.", "score": 0, "replies": []}]}]}]}]}]}]}]}]}]}]}]}]}]}, {"body": "They are different. In this case what you need a whole lot of is the low fidelity data.", "score": 1, "replies": []}]}, {"body": "This is just comically wrong. How would Dojo give any sort of performance boost beyond their current hardware?", "score": 1, "replies": [{"body": "Because all the training would be done there, they currently train on less powerful hardware and the car is a big part of the validation process.", "score": 0, "replies": [{"body": "Wait, you think Dojo is more powerful than H100 GPUs?", "score": 1, "replies": []}]}]}]}]}]}]}]}]}, {"body": "That anyone who has done any actual large scale ML training will see the limitations of this kind of data. It will create convergence well below the target performance, as well as overfitting to a different domain than the target.", "score": 1, "replies": []}]}, {"body": "They don't need all the data. What they needs is select examples and instances. They don't even necessarily need video. When they needed examples of occluded stop signs, the fleet gathered it very quickly.", "score": 1, "replies": [{"body": "The problem with that approach is dealing with overfitting, and generating the ground truth for computing a loss function.", "score": -1, "replies": []}]}]}, {"body": "[https://twitter.com/MartinViecha/status/1762921449197855012](https://twitter.com/MartinViecha/status/1762921449197855012)\n>Good summary\n\nhttps://twitter.com/elonmusk/status/1763071347993812999\n>Yeah", "score": 1, "replies": []}, {"body": "And growing…Tesla is going to sell another 2M vehicles this year. Their data for training has compounding growth.", "score": 1, "replies": []}]}, {"body": "I'm currently taking courses in artificial intelligence. (Thank you, employer!)\n\nThe importance of large amounts of data can't be overstated.", "score": 25, "replies": [{"body": "Quality and coverage of data matters far more beyond a certain point. More and more of the same old normal driving data isn't going to improve the system. The challenge with self driving cars is the \"long tail\" of the data distribution. Getting to 90% or 95% is much easier than solving the last 5%. There are an infinite number of situations that could occur while driving so simple pattern recognition and data collection may NEVER get you there. \n\nThis is the limitation of machine learning in safety critical systems. These systems aren't intelligent. They don't have analogical reasoning skills like humans do. Analogical reasoning is the part of human intelligence we can't account for right now in AI. It's what allows us to adapt to new unseen situations by using our knowledge of the world and previous experiences to come up with solutions to a new problem in a split second on the road.", "score": 10, "replies": [{"body": "With scale comes more edge cases and thus quality and coverage. One of the big reasons why Tesla decided to cut margins this much and keep scaling production instead of keeping production steady through the high rates.", "score": 11, "replies": [{"body": "That’s just not true. ML models are about developing heuristics, not capturing individual edge cases.", "score": 7, "replies": [{"body": "By edge cases I mean rarer events. To get data that covers that you need to have a big fleet. And I don't really think heuristics is correct in this case, if you have a fully end-to-end model, calling what the model does heuristics is misleading. Heuristic algorithms is what humans model in with conventional programming, what ML models do is not heuristics (though they might have heuristics in them).", "score": 1, "replies": [{"body": "That's a complete misunderstanding of how ML works. Latent space?", "score": 2, "replies": [{"body": "I guess you could have a different definition of heuristics? \"Not guaranteed to be optimal\" vs the one I'm used to, \"quick and dirty general rules programmed explicitly by humans\".\n\nWith the latter definition you could include heuristics in the stack that uses ML, but calling what the model does itself heuristics I don't think makes sense, I guess you disagree or have a different definition.", "score": 1, "replies": [{"body": "How do you interpret a latent distribution?", "score": 1, "replies": []}]}]}, {"body": "Any approach like what you describe is doomed. Rare events comprise a long-tailed distribution. That means that all of the really rare events look somewhat different from one another. Even if Tesla's data set captured all driving in human history, it'd still encounter unique scenarios every day and need to handle them. The system needs to be able to generalize to handle those cases from the data it has. Just like humans, who granted make dumb mistakes, but are able to handle complex edge cases fairly well even with very little driving experience.\n\nSo, the idea that they just need to collect more data until they've covered \"all\" the edge cases is impractical if not paradoxical. To make up some numbers to illustrate the point, doubling the mileage in the training data might fix 1% of FSD's errors at this stage. Doubling it again might fix 1% of what's left, and so on. The returns are extremely diminishing.\n\nIf you don't believe me, just look at how adding more data to the FSD 11 architecture (ditto for previous architectures) only resulted in marginal improvements. The big leaps in progress have come from changing the architecture of the system, not adding more data.", "score": 1, "replies": []}]}]}, {"body": "Yet no guarantees that you'll ever achieve sufficient coverage. You can't quantify it. In fact, the edge cases you're really interested in are the dangerous events (accidents) and those occur very rarely in millions of miles of driving. Hence why everyone (including Tesla) is using synthetic data (physics based game engine simulators) to supplement real data. You can generate massive quantities of edge cases with synthetic data to train your models on. This is what Waymo does. This is why Tesla's data advantage is way overstated. Collecting more and more normal driving data doesn't improve the system. You can generate billions of miles of synthetic data in days or weeks with computing clusters. The limitation isn't data right now. It's the technology.", "score": 2, "replies": [{"body": "Thanks for your input. My knowledge of all this stuff you could write on the back of an envelope. I would query one thing that you said; are 'dangerous events' limited to accidents? I would have thought there was a way to get the far more common 'near misses' into the training data. I do remember reading somewhere that Tesla have stated that they do use cases of 'bad driving'(probably not the exact words they used) to train their FSD on. I'm assuming only a small-ish minority of bad driving cases result in accidents.", "score": 3, "replies": [{"body": ">I would query one thing that you said; are 'dangerous events' limited to accidents? I would have thought there was a way to get the far more common 'near misses' into the training data.\n\nWaymo has a bunch of [really great papers](https://assets.ctfassets.net/e6t5diu0txbw/4XuPXbyhEjFxACpv1Wx70y/e5c54af2d8d8b35d9a1d91e0445a003f/Collision_Avoidance_Effectiveness_of_an_Automated_Driving_System_Using_a_Human_Driver_Behavior_Reference_Model_in_Reconstruc.pdf) on [exactly this](https://assets.ctfassets.net/e6t5diu0txbw/6rZvyFZfYtZ4kaPw97Kn3X/b0970f9ff020e2f59be2cabbaa7d30f2/Framework_for_a_conflict_typology_including_causal_factors_for_use_in_ADS_safety_evaluation.pdf). Yes, near-misses and simulated hits are part of the training and analysis 'regimen', and they track stats on them and generate many 'variant' scenes to improve future versions of the software.", "score": 6, "replies": []}]}, {"body": "Isn’t synthetic data built from real data too?  I’m always confused about synthetic data cause if it’s derived from real data I’m a bit confused as to how that will bring about new edge cases", "score": 1, "replies": [{"body": "In general no. There are different types of synthetic data. There is fully synthetic data that is fully model based. You have 3D models of the world and you have a validated simulator that captures the physics of the world. This is what is used in self driving cars. Sometimes the \"realism\" of the simulated sensor data can be improved by performing a domain adaptation step. But this is not always a requirement as other techniques can be used to bridge the \"domain gap\" between synthetic and real world.\n\nThen there is synthetic data that is based on learning a distribution of collected real world data. This could be a GAN or diffusion based model. The problem with this data is you're learning a distribution of data that was collected and sampling from that distribution. You can't really extrapolate outside the bounds of the real world data collected and it doesn't really improve model performance if your downstream models are already trained on that same data used to learn that distribution.", "score": 1, "replies": [{"body": "Sorry that was a bit over my head to be honest haha but like in these synthetic models they would essentially also have to program things like erratic driving behavior from others too right - e.g. a bank robbery in process, drunk driver, tornado etc?", "score": 1, "replies": [{"body": "Yep, they can procedurally model any scenario they want. And generate huge quantities of data with all types of variations in behaviors.", "score": 1, "replies": []}]}, {"body": "Expanding the distribution by collecting rarer and rarer events through a big fleet is exactly the point.\n\nWhen your data includes all kinds of rare events, the possible synthetic data you can generate from that is better as well. As these weird events happen randomly on the road, you can't really go out and seek them, you need a big fleet.", "score": 1, "replies": [{"body": "Or you just procedurally generate billions of miles of these rare events using validated 3D modeling and simulation tools very cheaply and quickly. As the big players already do. There are no guarantees you'll get data for different situations just sitting there and waiting for it to occur at random in a vehicle that's part of the fleet.", "score": 1, "replies": [{"body": "No guarantees but that is why you need a fleet that is as big as possible.", "score": 1, "replies": [{"body": "See above comment as to why it’s inefficient and unnecessary approach.", "score": 2, "replies": [{"body": "Synthetic data just won't be as weird or diverse as real world data, you seem to admit this in a previous comment talking about the range of the distribution, but now you say that is unnecessary (or that you can sidestep that issue by doing fully procedural data generation).\n\nHowever, Tesla has brought this (synthetic data won't be as diverse as real world data) up multiple times in their talks about self-driving.\n\nPerhaps Tesla is completely wrong on this and it is actually better to have a small number of vehicles collecting high-fidelity data and then just procedurally creating weird scenarios, but Tesla does not seem to think so.", "score": 1, "replies": []}]}]}, {"body": "So cool. I mean, at that point, with the simulation models are we teaching them how to \"crash well\"? Or just noting their behavior and reaction during rare events?", "score": 1, "replies": [{"body": "We aren't \"teaching\" the simulation models anything. We are using the simulation models to procedurally generate training and testing data of interest. You can perform testing of your entire system within the simulator in any potential situation you can think of and identify in what situations the system performs poorly. Then you can use that information to generate targeted training data to improve the performance of the system in those situations where the system needs to improve.", "score": 1, "replies": [{"body": "Damn, I feel like this methodology is pretty perfect. What do you think is the bottleneck if you don't mind? Seems like it should be ready", "score": 1, "replies": []}]}]}]}]}]}]}]}]}, {"body": "You underestimate deep learning, as I did until a few days ago.", "score": -2, "replies": [{"body": "Lol no I don't. I work in machine learning / computer vision as an applied scientist. I'm saying this from experience not from speculation.", "score": 4, "replies": [{"body": "Lmao this made me laugh,  the guys trying to talk down to you because he took a class. Maybe they'll cover that next week for him", "score": 2, "replies": []}, {"body": "Classic Reddit moment.", "score": 2, "replies": []}]}, {"body": "Perfect example of dunning Kruger. The guy who just started learning the topic trying to lecture engineers who have been working in the field for decades.", "score": 1, "replies": []}]}]}, {"body": "Top 3 things you've learned?", "score": 2, "replies": []}, {"body": "As someone who has worked in AI for 15 years, it really can. If the distributional properties of your training are target domains differ, more data will actually hurt training. Even if the data quality is high, there’s a diminishing return on additional data.", "score": 3, "replies": [{"body": "Heads up your comment got duplicated 3x. Reddit seems to be shitting the bed today so it's not you, dupes are happening everywhere.", "score": 6, "replies": [{"body": "That’s what I get for skimping on cell service.", "score": 2, "replies": []}]}]}, {"body": "Curious about this course - is it like how to develop with it or more practical applications of it in work or understanding the science/tech behind it", "score": 1, "replies": [{"body": "All of the above.\n\nIt's not something generally accessible, it is a set of courses put together to bootstrap a bunch of experienced developers with varying levels of existing knowledge. It's everything from executive briefings to creating NN architectures to prompt engineering for multiple tech stacks.", "score": 1, "replies": []}]}]}, {"body": "This is the guy who said Dojo was worth 500 billion? Sure you should put any weight on his technical analysis?", "score": 3, "replies": [{"body": "This is the guy who [sheepishly posted a grovelling](https://twitter.com/carlquintanilla/status/1755996399672402371) \"I was wrong, I am dumb\" apology about Toyota just the other day. Nbd, just Morgan Stanley's automotive guy calling it flagrantly wrong about the entire trajectory of automotive for several years in a row and then making a quiet retraction.\n\nI wonder how much he gets paid.", "score": 4, "replies": []}]}, {"body": "Pretty much what I was saying about it for a few years but the faithful would just say Apple can do anything because they have as much money as god. With only 69 or so vehicles mostly driving around the Bay Area, they simply couldn't get enough real world driving data compared to hundreds of thousands of Teslas collecting hundreds of millions to billions of miles of data, testing neural nets and reporting back when the driver disagrees even if you don't have FSD. \n\nApple's tendency to secrecy and not trying things out in the public cost them here.", "score": 2, "replies": [{"body": "> Apple's tendency to secrecy and not trying things out in the public cost them here.\n\nBecause they've built a reputation on developing the *perfect* product each time and that reputation is tied to the perception of negligible to zero failures. Autonomous Apple vehicles would be a BIG visible flag subject to potential failure, reputation loss, and avenue for bad actors to cause havoc with brand and financials.\n\nAs such, Apple would have never been public with this in a way that matters; public perception of growth of safety. They're very zero sum like this, and is why, as we both agree, Apple's project was doomed from before even the first bolt was twisted.", "score": 5, "replies": []}]}, {"body": "I \\*am\\* gonna toot my own horn here and say that I called it...  [https://www.reddit.com/r/teslainvestorsclub/comments/1b1lmhx/comment/ksfr3nk/](https://www.reddit.com/r/teslainvestorsclub/comments/1b1lmhx/comment/ksfr3nk/)", "score": 2, "replies": [{"body": "You called it... twenty hours ago, after the announcement was made?\n\nWhat exactly did you call?", "score": 10, "replies": [{"body": "My comment is mostly tongue in cheek. The person I was responding to considered it “bad news” for Tesla that Apple cancelled their program because it spells bad news for Tesla’s ability to deliver on FSD. \n\nI turned it around and made a point about fleet size and the capacity for Tesla to collect data that Apple simply doesn’t have and would have to spend inordinate amounts of money to achieve.", "score": 3, "replies": [{"body": "(Pssst.. you didn't respond to anyone, your comment is top level.)\n\n>I turned it around and made a point about fleet size and the capacity for Tesla to collect data that Apple simply doesn’t have and would have to spend inordinate amounts of money to achieve.\n\nThe whole point is absurd, because if Apple started making cars, well... they'd have that fleet scale data in a moment. They'd simply follow the same path Tesla has — get fleet out, gather data, iterate. Data, of course, is not the bottleneck though — most OEMs and AV firms just use primarily synthetic data at this point.", "score": 0, "replies": [{"body": ">  you didn't respond to anyone, your comment is top level\n\nLook again.\n\nhttps://www.reddit.com/r/teslainvestorsclub/comments/1b1lmhx/mark_gurman_breaking_news_apple_cancels_the_apple/ksfib0p/", "score": 1, "replies": [{"body": "Reddit comments have a hierarchy, parent's comment is not a response to anyone else's.", "score": 1, "replies": [{"body": "Are you blind or just having a technical issue?\n\n\"thefirstOP\" was responding to \"Rockhardwood\" whose post was downvoted to -10 so maybe you aren't seeing the post he replied to?", "score": 0, "replies": []}]}]}]}]}]}]}, {"body": "\"Tesla has over 5 million vehicles (fitted with FSD hardware and software) in service driving an estimated 50 billion miles per year.\"\n\nUuuhhhh, is this true? I don't have FSD, and can't retrofit to newer hardware versions. Is my data still part of the pipeline?", "score": 1, "replies": [{"body": "Yes, even in country where FSD is not active.\n\nYou want an example?\n\nThey needed stop signs put in stupid positions, do you want to know where they took the data?\n\nFrom Italy.\n\nAnd as an Italian I must say, they are right.", "score": 7, "replies": []}, {"body": "Yes, but the numbers here are inflated. Tesla isn't doing intake of 50B miles, only a very small part of that and at low-fidelity. Intake of 50B miles at full-fidelity would require more compute/storage than even exists on earth.", "score": 2, "replies": [{"body": "The large scale allows them to cherry pick the rarer events that aren't covered sufficiently.", "score": 1, "replies": []}, {"body": "How much 5 think 1 mile is in terms of data?", "score": 1, "replies": []}]}]}, {"body": "Bandwidth, Bandwidth, Bandwidth.", "score": 1, "replies": []}]}
