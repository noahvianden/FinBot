{"title": "Solving A Compounding Riddle With Black-Scholes", "selftext": " \n\nA few weeks ago I was getting on an airplane armed with a paper and pen, ready to solve the problem in the tweet below. And while I think you will enjoy the approach, the real payoff is going to follow shortly after — I’ll show you how to not only solve it with option theory but expand your understanding of the volatility surface. This is going to be fun. Thinking caps on. Let’s go.\n\n# The Question That Launched This Post\n\n&#x200B;\n\nhttps://preview.redd.it/1hy788cy808b1.png?width=459&format=png&auto=webp&s=4e95144be95878f2de243929786ab97dc7d7a536\n\n&#x200B;\n\n \n\nFrom that tweet, you can see the distribution of answers has no real consensus. So don’t let others’ choices affect you. Try to solve the problem yourself. I’ll re-state some focusing details:\n\n* Stock A compounds at 10% per year with no volatility\n* Stock B has the same annual expectancy as A but has volatility. Its annual return is binomial — either up 30% or down 10%.\n* After 10 years, what’s the chance volatile stock B is higher than A?\n\nYou’ll get the most out of this post if you try to solve the problem. Give it a shot. Take note of your gut reactions before you start working through it. In the next section, I will share my gut reaction and solution.\n\n# My Approach To The Problem\n\n## Gut Reaction\n\nSo the first thing I noticed is that this is a “compounding” problem. It’s multiplicative. We are going to be letting our wealth ride and incurring a percent return. We are applying a rate of return to some corpus of wealth that is growing or shrinking. I’m being heavy-handed in identifying that because it stands in contrast to a situation where you earn a return, take profits off the table, and bet again. Or situations, where you bet a fixed amount in a game as opposed to a fraction of your bankroll. This particular poll question is a compounding question, akin to re-investing dividends not spending them. This is the typical context investors reason about when doing “return” math. Your mind should switch into “compounding” mode when you identify these multiplicative situations.\n\nSo if this is a compounding problem, and the arithmetic returns for both investments are 10% I immediately know that volatile stock “B” is likely to be lower than stock “A” after 10 years. This is because of the “volatility tax” or what I’ve called the [volatility drain](https://moontowermeta.com/the-volatility-drain/). Still, that only conclusively rules out choice #4. Since we could rule that without doing any work and over 2,000 respondents selected it, I know there’s a good reason to write this post!\n\n# Showing My Work\n\nHere’s how I reasoned through the problem step-by-step.\n\n**Stock A’s Path (10% compounded annually)**\n\n&#x200B;\n\nhttps://preview.redd.it/3clqio60908b1.png?width=111&format=png&auto=webp&s=20c384a86ff79efc11cf5b4ec8f95f2f08ae0f86\n\n&#x200B;\n\n \n\n**Stock B’s Path (up 30% or down 10%)**\n\nThe fancy term for this is “binomial tree” but it’s an easy concept visually. Let’s start simple and just draw the path for the first 2 years. Up nodes are created by multiplying the stock price by 1.3, down modes are created by multiplying by .90.\n\n&#x200B;\n\nhttps://preview.redd.it/r4ckasj1908b1.png?width=636&format=png&auto=webp&s=1ac6355fe819f1b148bd0c4f9d3cfcae59bb2d15\n\n \n\n**Inferences**\n\nYear 1: 2 cumulative outcomes. Volatile stock B is 50/50 to outperform  \nYear 2: There are 3 cumulative outcomes. Stock B only outperforms in one of them.\n\nLet’s pause here because while we are mapping the outcome space, we need to recognize that not every one of these outcomes has equal probability.\n\n2 points to keep in mind:\n\n* In a binomial tree, the number of possibilities is 2ᴺ where N is the number of years. This makes sense since each node in the tree has 2 possible outcomes, the tree grows by 2ᴺ.\n* However, the number of outcomes is N + 1. So in Year 1, there are 2 possible outcomes. In year 2, 3 possible outcomes.\n\nProbability is the number of ways an outcome can occur divided by the total number of possibilities.\n\nVisually:\n\n&#x200B;\n\nhttps://preview.redd.it/l1vb1jg3908b1.png?width=640&format=png&auto=webp&s=0a03eebf82afb54cd36616c00c7f94753929908e\n\n \n\n**So by year 2 (N=2), there are 3 outcomes (N+1) and 4 cumulative paths (2ᴺ)**\n\nWe are moving slowly, but we are getting somewhere.\n\nIn year 1, the volatile investment has a 50% chance of winning. The frequency of win paths and lose paths are equal. But what happens in an even year?\n\nThere is an odd number of outcomes, with the ***middle outcome representing the number of winning years and the number of losing years being exactly the same. If the frequency of the wins and losses is the same the volatility tax dominates***. If you start with $100 and make 10% then lose 10% the following year, your cumulative result is a loss.\n\n$100 x 1.1 x .9 = $99\n\nOrder doesn’t matter.\n\n$100 x .9 x 1.1 = $99\n\nIn odd years, like year 3, there is a clear winner because the number of wins and losses cannot be the same. Just like a 3-game series.\n\n**Solving for year 10**\n\nIf we extend this logic, it’s clear that year 10 is going to have a big volatility tax embedded in it because of the term that includes stock B having 5 up years and 5 loss years.\n\nN = 10  \nOutcomes (N+1) = 11 (ie 10 up years, 9 up years, 8 up years…0 up years)  \n\\# of paths (2ᴺ) = 1024\n\nWe know that 10, 9, 8,7,6 “ups” result in B > A.  \nWe know that 4, 3, 2,1, 0 “ups” result in B < A\n\nThe odds of those outcomes are symmetrical. So the question is how often does 5 wins, 5 losses happen? That’s the outcome in which stock A wins because the volatility tax effect is so dominant.\n\nThe number of ways to have 5 wins in 10 years is a combination formula for “10 choose 5”:\n\n₁₀C₅ or in Excel *=combin(10,5)* = **252**\n\nSo there are 252 out of 1024 total paths in which there are 5 wins and 5 losses. **24.6%**\n\n24.6% of the time the volatility tax causes A > B. The remaining paths represent 75.4% of the paths and those have a clear winner that is evenly split between A>B and B>A.\n\n75.4% / 2 = 37.7%\n\n**So volatile stock B only outperforms stock A 37.7% of the time despite having the same arithmetic expectancy!**\n\n*This will surprise nobody who recognized that the geometric mean corresponds to the median of a compounding process. The geometric mean of this investment is not 10% per year but 8.17%. Think of how you compute a CAGR by taking the terminal wealth and raising it to the 1/N power. So if you returned $2 after 10 years on a $1 investment your CAGR is 2\\^(1/10) — 1 = 7.18%. To compute a geometric mean for stock B we invert the math: .9\\^(1/2) \\* 1.3\\^(1/2) -1 = 8.17%. (we’ll come back to this after a few pictures)*\n\n## The Full Visual\n\nA fun thing to recognize with binomial trees is that the coefficients (ie the number of ways a path can be made that we denoted with the “combination” formula) can be created easily with Pascal’s Triangle. Simply sum the 2 coefficients directly from the line above it.\n\n**Coefficients of the binomial expansion (# of ways to form the path)**\n\n&#x200B;\n\nhttps://preview.redd.it/lf90hm46908b1.png?width=640&format=png&auto=webp&s=540d06ee92fe7b3ce5b0af1c0c1059b8d90dc97d\n\n&#x200B;\n\nhttps://preview.redd.it/dkfr3rp6908b1.png?width=640&format=png&auto=webp&s=3cfbdf0eff260ab265f4c058cbc9d95c45cb1e25\n\n&#x200B;\n\nhttps://preview.redd.it/u05d6mf7908b1.png?width=640&format=png&auto=webp&s=d0cb1179a2a042a6f800978e357cf5262415617b\n\n \n\n*Above we computed the geometric mean to be 8.17%. If we compounded $100 at 8.17% for 10 years we end up with $219 which is the median result that corresponds to 5 up years and 5 down years!*\n\n# The Problem With This Solution\n\nI solved the 10-year problem by recognizing that, in even years, the volatility tax would cause volatile stock B to lose when the up years and down years occurred equally. (Note that while an equal number of heads and tails is the most likely outcome, it’s still not likely. There’s a 24.6% chance that it happens in 10 trials).\n\nBut there’s an issue.\n\nMy intuition doesn’t scale for large N. Consider 100 years. Even in the case where B is up 51 times and down 49 times the volatility tax will still cause the cumulative return of B < A. We can use guess-and-test to see how many winning years B needs to have to overcome the tax for N = 100.\n\nN = 100\n\nIf we put $1 into A, it grows at 1.1¹⁰⁰ = $13,871\n\nIf we put $1 into B and it has 54 winning years and 46 losing years, it will return 1.3⁵⁴ \\* .9⁴⁶ = $11,171. It underperforms A.\n\nIf we put $1 into B and it has 55 winning years and 45 losing years, it will return 1.3⁵⁵ \\* .9⁴⁵ = $16,136. It outperforms A.\n\nSo B needs to have 55 “ups”/45 “downs” or about 20% more winning years to overcome the volatility tax. It’s not as simple as it needs to win more times than stock A, like we found for shorter horizons.\n\nWe need a better way.\n\n# The General Solution Comes From Continuous Compounding: The Gateway To Option Theory\n\nIn the question above, we compounded the arithmetic return of 10% annually to get our expectancy for the stocks.\n\nBoth stocks’ expected value after 10 years is 100 \\* 1.1¹⁰ = $259.37.\n\nBe careful. You don’t want the whole idea of the geometric mean to trip you up. The compounding of volatility does NOT change the expectancy. It changes the distribution of outcomes. This is crucial.\n\nThe expectancy is the same, the distribution differs.\n\nIf we keep cutting the compounding periods from 1 year to 1 week to 1 minute…we approach continuous compounding. That’s what logreturns are. Continuously compounded returns.\n\nHere’s the key:\n\nReturns conform to a lognormal distribution. You cannot lose more than 100% but you have unlimited upside because of the continuous compounding. Compared to a bell-curve the lognormal distribution is positively skewed. The counterbalance of the positive skew is that the geometric mean or center of mass of the distribution is necessarily lower than the arithmetic expectancy. How much lower? It depends on the volatility because the volatility tax[1](https://moontowermeta.com/solving-a-compounding-riddle-with-black-scholes/#easy-footnote-bottom-1-4741) pulls the geometric mean down from the arithmetic mean or expectancy. The higher the volatility, the more positively skewed the lognormal or compounded distribution is. The more volatile the asset is in a positively skewed distribution the larger the right tail grows since the left tail is bounded by zero. The counterbalance to the positive skew is that the most likely outcome is the geometric mean.\n\nI’ll pause here for a moment to just hammer home the idea of positive skew:\n\nIf stock B doubled 20% of the time and lost 12.5% the remaining 80% of the time its average return would be exactly the same as stock A after 1 year (20% \\* $200 + 80% \\* $87.5 = $110). The arithmetic mean is the same. But the most common lived result is that you lose. The more we crank the volatility higher, the more it looks like a lotto ticket with a low probability outcome driving the average return.\n\nLook at the terminal prices for stock B:\n\n&#x200B;\n\nhttps://preview.redd.it/5jxuoge9908b1.png?width=640&format=png&auto=webp&s=bf1171cec392eeaa8cf1e4caa35d80aaaf680d5b\n\n \n\nThe arithmetic mean is the same as A, $259.\n\nThe geometric or mean or most likely outcome is only $219 (again corresponding to the 8.17% geometric return)\n\nThe magnitude of that long right tail ($1,379 is > 1200% total return, while the left tail is a cumulative loss of 65%) is driving that 10% arithmetic return.\n\n*Compounding is pulling the typical outcome down as a function of volatility but it’s not changing the overall expectancy.*\n\n## A Pause To Gather Ourselves\n\n* We now understand that compounded returns are positively skewed.\n* We now understand that logreturns are just compounded returns taken continuously as opposed to annually.\n* This continuous, logreturn world is the basis of option math.\n\n# Black-Scholes\n\nThe lognormal distribution underpins the Black-Scholes model used for pricing options.\n\nThe mean of a lognormal distribution is the geometric mean. By now we understand that the geometric mean is always lower than the arithmetic mean. So in compounded world we understand that most likely outcome is lower than the arithmetic mean.\n\nGeometric mean = arithmetic mean — .5 \\* volatility²\n\n*The question we worked on is not continuous compounding but if it were, the geometric mean = 10% — .5 \\* (.20)² = 8%. Just knowing this was enough to know that most likely B would not outperform A even though they have the same average expectancy.*\n\nLet’s revisit the original question, but now we will assume continuous compounding instead of annual compounding. The beauty of this is we can now use Black Scholes to solve it!\n\n## Re-framing The Poll As An Options Question\n\nWe now switch compounding frequency from annual to continuous so we are officially in Black-Scholes lognormal world.\n\n**Expected return (arithmetic mean)**\n\nAnnual compounding: $100 \\* (1.1)¹⁰ = $259.37\n\nContinuous compounding (B-S world): 100\\*e\\^(.10 \\* 10) = $271.83\n\n**Median return (geometric mean)**\n\nAnnual compounding: $100 x 1.081⁷¹⁰ = $219.24\n\nContinuous compounding (B-S world): $100 \\* e\\^(.10 — .5 \\* .²²) = $222.55\n\n* remember *Geometric mean = arithmetic mean — .5 \\* volatility²*\n* geometric mean < arithmetic mean of course\n\nThe original question:\n\n*What’s the probability that stock B with its 10% annual return and 20% volatility outperforms stock A with its 10% annual return and no volatility in 10 years?*\n\nAsking the question in options language:\n\n***What is the probability that a 10-year call option on stock B with a strike price of $271.83 expires in-the-money?***\n\nIf you have heard that “delta” is the probability of “expiring in-the-money” then you think we are done. We have all the variables we need to use a Black-Scholes calculator which will spit out a delta. The problem is delta is only approximately the probability of expiring in-the-money. In cases with lots of time to expiry, like this one where the horizon is 10 years, they diverge dramatically. [2](https://moontowermeta.com/solving-a-compounding-riddle-with-black-scholes/#easy-footnote-bottom-2-4741)\n\nWe will need to extract the probability from the Black Scholes equation. Rest assured, we already have all the variables.\n\n## Computing The Probability That Stock “B” Expires Above Stock “A”\n\nIf we simplify Black-Scholes to a bumper sticker, it is the *probability-discounted stock price beyond a fixed strike price*. Under the hood of the equation, there must be some notion of a random variable’s probability distribution. In fact, it’s comfortingly simple. The crux of the computation is just calculating z-scores.\n\nI think of a z-score as the “X” coordinate on a graph where the “Y” coordinate is a probability on a distribution. Refresher pic[3](https://moontowermeta.com/solving-a-compounding-riddle-with-black-scholes/#easy-footnote-bottom-3-4741):\n\n&#x200B;\n\nhttps://preview.redd.it/f5m9uqxb908b1.png?width=640&format=png&auto=webp&s=959e9f21ef73bc2250ec0a493a3090ee9a9b0733\n\n \n\nConceptually, a z-score is a distance from a distribution’s mean normalized by its standard deviation. In Black-Scholes world, z-scores are a specified logreturn’s distance from the geometric mean normalized by the stock’s volatility. Same idea as the Gaussian z-scores you have seen before.\n\nConveniently, logreturns are themselves normally distributed allowing us to use the good ol’ *NORM.DIST* Excel function to turn those z-scores into probabilities and deltas.\n\nIn Black Scholes,\n\n* delta is N(d1)\n* probability of expiring in-the-money is N(d2)\n* d1 and d2 are z-scores\n\nHere are my calcs[4](https://moontowermeta.com/solving-a-compounding-riddle-with-black-scholes/#easy-footnote-bottom-4-4741):\n\n&#x200B;\n\nhttps://preview.redd.it/z115hdud908b1.png?width=636&format=png&auto=webp&s=d4cf65b75727e34ca1bcc18877aec44218322f16\n\n \n\nBoom.\n\nThe probability of stock B finishing above stock A (ie the strike or forward price of an a $100 stock continuously compounded at 10% for 10 years) is…\n\n**37.6%!**\n\nThis is respectably close to the 37.7% we computed using Pascal’s Triangle. The difference is we used the continuous compounding (lognormal) distribution of returns instead of calculating the return outcomes discretely.\n\n## The Lognormal Distribution Is A Lesson In How Compounding Influences Returns\n\nI ran all the same inputs through Black Scholes for strikes up to $750.\n\n* This lets us compute all the straddles and butterflies in Black-Scholes universe (ie what market-makers back in the day called “flat sheets”. That means no additional skew parameters were fit to the model or the model was not fit to the market).\n* The flys lets us draw the distribution of prices.\n\nA snippet of the table:\n\n&#x200B;\n\nhttps://preview.redd.it/8tb8zrif908b1.png?width=507&format=png&auto=webp&s=92d83c5df2d61fd560cc7afc0a226c1a37389958\n\n \n\nI highlighted a few cells of note:\n\n* The 220 strike has a 50% chance of expiring ITM. That makes sense, it’s the geometric mean or arithmetic median.\n* The 270 strike is known as At-The-Forward because it corresponds to the forward price of $271.83 derived from continuously compounding $100 at 10% per year for 10 years (ie Seʳᵗ). If 10% were a risk-free rate this would be treated like the 10 year ATM price in practice. Notice it has a 63% delta. This suprises people new to options but for veterans this is expected (assuming you are running a model without spot-vol correlation).\n* You have to go to the $330 strike to find the 50% delta option! If you need to review why see [*Lessons From The .50 Delta Option*](https://moontowermeta.com/lessons-from-the-50-delta-option/).\n\nThis below summary picture adds one more lesson:\n\nThe cheapest straddle (and therefore most expensive butterfly) occurs at the modal return, about $150. If the stock increased from $100 to $150, you’re CAGR would be 4.1%. This is the single most likely event despite the fact that it’s below the median AND has a point probability of only 1.7%\n\n&#x200B;\n\nhttps://preview.redd.it/zczv4x9h908b1.png?width=640&format=png&auto=webp&s=a208eec69ae8abd920d499455130628016371f91\n\n \n\n## Speaking of Skew\n\nVanilla Black-Scholes option theory is a handy framework for understanding the otherwise unintuitive hand of compounding. The lognormal distribution is the distribution that corresponds to continuously compounded returns. However, it is important to recognize that nobody actually believes this distribution describes any individual investment. A biotech stock might be bimodally distributed, contingent on an FDA approval. If you price SPX index options with positively skewed model like this you will not last long.\n\nA positively skewed distribution says “on average I’ll make X because sometimes I’ll make multiples of X but most of the time, my lived experience is I’ll make less than X”.\n\nIn reality, the market imputes negative skew on the SPX options market. This shifts the peak to the right, shortens the right tail, and fattens the left tail. That implied skew says “on average I make X, I often make more than X, because occasionally I get annihilated”.\n\nIt often puzzles beginning traders that adding “put skew” to a market, which feels like a “negative” sentiment, raises the value of call spreads. But that actually makes sense. A call spread is a simple over/under bet that reduces to the odds of some outcome happening. If the spot price is unchanged, and the puts become more expensive because the left tail is getting fatter, then it means the asset must be more likely to appreciate to counterbalance those 2 conditions. So of course the call spreads must be worth more.\n\n# Final Wrap\n\nCompounding is a topic that gives beginners and even experienced professionals difficulty. By presenting the solution to the question from a discrete binomial angle and a continuous Black-Scholes angle, I hope it soldified or even furthered your appreciation for how compounding works.\n\nMy stretch goal was to advance your understanding of option theory. While it overlaps with many of my other option theory posts, if it led to even any small additional insight, I figure it’s worth it. I enjoyed sensing that the question could be solved using options and then proving it out.\n\nI want to thank [@10kdiver](https://twitter.com/10kdiver) for the work he puts out consistently and the conversation we had over Twitter DM regarding his question. If you are trying to learn basic and intermediate level financial numeracy his collection of threads is unparalled. Work I aspire to. Check them out here: [https://10kdiver.com/twitter-threads/](https://10kdiver.com/twitter-threads/)\n\nRemember, my first solution (Pascal’s Triangle) only worked for relatively small N. It was not a general solution. The Black-Scholes solution is a general one but required changing “compounded annually” to “compounded continuously”. 10kdiver provided the general solution, using logs (so also moving into continuous compounding) but did not require discussion of option theory.\n\n&#x200B;\n\nhttps://preview.redd.it/uc5uxwnj908b1.png?width=468&format=png&auto=webp&s=4ff48146a3c4377dc85282e32700f8f44a460a7c", "id": "14hzdal", "created_utc": 1687629785.0, "score": 253, "upvote_ratio": 0.96, "num_comments": 65, "comments": [{"body": "If you have a stream of returns does order matter before getting to the terminal value? \n\nNo because returns are multiplicative. \n\n.5 * 1.5 = 1.5 * .5", "score": 18, "replies": []}, {"body": "damn, i think there’s good educational value in this post but most people in these comments seem to know everything already lmao\n\nthanks for the breakdown op, i hope others can find value in it as i did", "score": 34, "replies": [{"body": "For those of us who know, he’s one the best in the business.\n\nFor those who don’t… well reddit gonna reddit.", "score": 11, "replies": [{"body": "yeah i just followed him on twitter and now i realize how completely arrogant some of these comments are haha. i admire his patience", "score": 1, "replies": []}]}]}, {"body": "Geez you finance guys do a lot when you can do something very simple. Solve 1.1^(10)=(1.3^(10-x))*(.9^x) and round up to the next highest integer, n. Then use a simple binomial distribution with success chance 50% to calculate the probability that P(x>=n).", "score": 47, "replies": []}, {"body": "Hey can I have some of your Adderall?", "score": 10, "replies": []}, {"body": "That's a fine way to approach too but reasoning through the binomial distribution offers another way to build discrete intuition and in this case is helpful to bootstrap an understanding of Black Scholes assumed distribution. \n\nIn general I use Excel in many places where python would work just as well as better but Excel is my crutch. (I have posts where I use Python and I publish my code -- I suck at coding it might be as uncomfortable as staring at the sun 😉)", "score": 21, "replies": [{"body": "The expected return of B is not 1.10. You need to take the geometric mean of the weights to the probabilities, not the arithmetic mean:\n\nexpected_return_for_single_trial_of_B = outcome_A^prob_A * outcome_B^prob_B = 1.3^.5 * 0.9^.5 = 1.081665\n\nWhich is not 1.10", "score": 2, "replies": [{"body": "No. Using the definition of expected value, the expected return is outcome\\_A\\*prob\\_A+outcome\\_B\\*prob\\_B. [https://en.wikipedia.org/wiki/Expected\\_value#Random\\_variables\\_with\\_countably\\_many\\_outcomes](https://en.wikipedia.org/wiki/Expected_value#Random_variables_with_countably_many_outcomes)", "score": 0, "replies": [{"body": "We're not summing these random trials, we're multiplying them.\n\nhttps://financeformulas.net/Geometric_Mean_Return.html\n\n    experiments = []\n    # Run 40000 experiments \n    for experiment in range(40000):\n        running_product = 1\n        for outcome in range(1500):\n            # Choose between 0.9 and 1.3 1500 times\n            running_product *= random.choice([0.9, 1.3])\n        # To get the average rate of return for the experiment we take the 1500th root\n        # ie, the geometric mean\n        experiments.append(running_product ** (1/1500))\n    # Now we take the arithmetic average across the experiments\n    print(sum(experiments)/len(experiments))\n\n    1.0816659950068918", "score": 2, "replies": []}]}]}]}, {"body": "I got lost around this part:\n\n>\tGeometric mean = arithmetic mean — .5 * volatility²\n\n\nHow did you come up with this ?", "score": 6, "replies": [{"body": "This formula is commonly referred to as volatility drag.  It’s an approximation; you can take it as given, or go look at papers which derive it. In any case, it’s a way to quantify the fact that annualized multiplicative returns (compounding) don’t like lots of volatility.", "score": 8, "replies": [{"body": "Ah got it. Thanks.", "score": 4, "replies": []}]}, {"body": "[deleted]", "score": 2, "replies": [{"body": "Thanks, but that is still over my head. I didn’t major in finance, did accounting, so the academic side is not too native to me.", "score": 1, "replies": []}]}]}, {"body": "o-k solved this problem in calc 1", "score": 9, "replies": []}, {"body": "I like this, thanks.", "score": 3, "replies": []}, {"body": "[deleted]", "score": 34, "replies": [{"body": "How does one compute self-actualization? \n\n..apparently with a few lines of python lol", "score": 33, "replies": [{"body": "and with calling an internet stranger a F'ing idiot.", "score": 17, "replies": []}]}, {"body": "You just called someone, who's incredibly intelligent when it comes to this stuff an idiot. Congrats, you're the idiot.", "score": 14, "replies": []}, {"body": "You are a fucking idiot if you think it takes anywhere near 5 minutes for that script to run. /s", "score": 11, "replies": [{"body": "While I agree he shouldn’t be calling the OP an idiot for his in depth post, I solved it using the same ‘brute force’ method with python. The code took me about 5-10 min to write and runs in 1-2 seconds on google colab. He’s not that far off base.", "score": 1, "replies": []}]}, {"body": "Jesus that was ruthless! 😂😂", "score": 11, "replies": []}, {"body": "You're totally missing the point here. Yes that code works for this example, but we want to understand how we can use a formula to compute this example so that we can apply it to more computationally difficult problems.", "score": 11, "replies": [{"body": "there are a million of these guys proclaiming that there is no need for studying and understanding most problems because you can just brute-force it with Machine Learning.\n\n(correction, all of those guys are calling it AI this week.)", "score": 8, "replies": [{"body": "But that isn't Machine Learning. It is just a script with a few loops!", "score": 10, "replies": []}, {"body": "Not that long ago, it was block chain instead of AI.", "score": 2, "replies": [{"body": "Heh, you're right. Funny how that works.", "score": 1, "replies": []}]}]}, {"body": "What?", "score": 3, "replies": []}]}, {"body": "He’s practicing writing research papers to pad his resume", "score": 7, "replies": [{"body": "That's pronounced \"professor\".", "score": 3, "replies": []}]}]}, {"body": "Great, but how does this help with my SPX iron fly?", "score": 6, "replies": []}, {"body": "That’s a lot of math.\n\nWhy not write a Python script in 2 mins and settle it?", "score": 6, "replies": [{"body": "For understanding the answer instead of simply observing the answer.  (To be fair, I solved it the way you described ;) )", "score": 1, "replies": []}]}, {"body": "I didn't derive it but simply accept it as an identity\n\nThis can get you started but it comes out of stochastic calculus I believe \n\nhttps://quant.stackexchange.com/questions/32948/how-do-the-units-compare-inside-the-rate-0-5sigma-squared-correction", "score": 5, "replies": []}, {"body": "Separate question for the pre black scholes portion, where you got an answer. Wouldn’t the order matter ? So wouldn’t it be permutation not combination?", "score": 2, "replies": []}, {"body": "While I do know stats and probability, I've never learned it in the context of finance. Is this what's involved with \"Financial Engineering\" and stuff like that?\n\nUltimately I'm asking, where can I learn this with a financial frame of reference?", "score": 2, "replies": [{"body": "There are tons of books out there that cover this. Just google around a bit. It's stochastic calculus.", "score": 1, "replies": []}]}, {"body": "Thank you for great discussion", "score": 2, "replies": []}, {"body": "Another L for Chat GPT-4, it gets  17.19%.\n\n&#x200B;\n\nTo answer this question, we need to model each scenario and calculate the probability of stock B being higher than stock A.\r  \n\r  \nFor Stock A, its value after 10 years, given a compound growth of 10% per year, can be calculated using the compound interest formula:\r  \n\r  \nA = P(1 + r)\\^n\r  \n\r  \nWhere:\r  \n\r  \nA is the amount of money accumulated after n years, including interest.\r  \nP is the principal amount (the initial amount of money).\r  \nr is the annual interest rate (in decimal form).\r  \nn is the number of years the money is invested for.\r  \nAssuming a starting price of 1 (to keep things simple), after 10 years, stock A will have a value of:\r  \n\r  \nA = 1(1 + 0.10)\\^10 = 2.5937 (rounded to four decimal places)\r  \n\r  \nNow, let's look at Stock B.\r  \n\r  \nStock B's yearly return is binomial - it's either up 30% or down 10%. This implies a multitude of potential paths over 10 years.\r  \n\r  \nHowever, calculating the probability of stock B ending up higher than A involves understanding its binomial distribution over 10 years.\r  \n\r  \nStock B can outperform stock A in a few ways, the simplest of which is to go up 30% each year for 10 years. If that happens, its value after 10 years would be:\r  \n\r  \nB\\_up = 1(1 + 0.30)\\^10 = 13.79 (rounded to two decimal places)\r  \n\r  \nHowever, it's impossible for stock B to always go up. It also can go down. The question, then, is how many years can stock B go down (lose 10%) and still end up with a higher value than stock A (2.5937).\r  \n\r  \nFor that, we can solve the following equation:\r  \n\r  \nB\\_mix = 1 \\* (1 - 0.10)\\^x \\* (1 + 0.30)\\^(10 - x) > 2.5937\r  \n\r  \nSolving this equation for x, we find that x≈3. This means that even if stock B loses 10% for about 3 years out of the 10, it can still outperform stock A, as long as it goes up 30% for the other 7 years.\r  \n\r  \nNow we have to calculate the binomial probability that stock B goes down for 3 or fewer years out of 10 (since that's when it outperforms stock A).\r  \n\r  \nThe binomial probability formula is:\r  \n\r  \nP(k; n, p) = C(n, k) \\* (p)\\^k \\* (1-p)\\^(n-k)\r  \n\r  \nWhere:\r  \n\r  \nP is the probability,\r  \nk is the number of \"successes\" (in this case, the stock going down),\r  \nn is the number of trials (in this case, 10 years),\r  \np is the probability of \"success\" (in this case, the chance the stock goes down, which is 0.5, because the problem doesn't specify a different probability),\r  \nC(n, k) is the number of combinations of n items taken k at a time.\r  \nWe're interested in the cumulative probability that stock B goes down 0, 1, 2, or 3 years out of 10, because in those scenarios, it still outperforms stock A.\r  \n\r  \nSo, we need to sum up the probabilities for k = 0, 1, 2, and 3:\r  \n\r  \nP = Σ P(k; 10, 0.5) from k = 0 to 3\r  \n\r  \nThis involves some calculations, but once you do them, you'll have the probability that stock B is higher than stock A after 10 years,\r  \n\r  \n\r  \n\r  \n\r  \n\r  \nUser\r  \nFinish the calculation\r  \nChatGPT\r  \nAlright, let's calculate the cumulative probability of Stock B going down for 0, 1, 2, or 3 years out of 10. We'll use the binomial probability formula for each of these and then sum them up.\r  \n\r  \nThe binomial probability formula is:\r  \n\r  \nP(k; n, p) = C(n, k) \\* (p)\\^k \\* (1-p)\\^(n-k)\r  \n\r  \nWhere:\r  \n\r  \nP is the probability\r  \nk is the number of \"successes\" (the stock going down)\r  \nn is the number of trials (10 years)\r  \np is the probability of \"success\" (the chance the stock goes down, which is 0.5, because the problem doesn't specify a different probability)\r  \nC(n, k) is the number of combinations of n items taken k at a time.\r  \nFirst, let's calculate the probabilities for k = 0, 1, 2, and 3:\r  \n\r  \nP(0; 10, 0.5) = C(10, 0) \\* (0.5)\\^0 \\* (0.5)\\^(10-0) = 0.00098\r  \nP(1; 10, 0.5) = C(10, 1) \\* (0.5)\\^1 \\* (0.5)\\^(10-1) = 0.00977\r  \nP(2; 10, 0.5) = C(10, 2) \\* (0.5)\\^2 \\* (0.5)\\^(10-2) = 0.04395\r  \nP(3; 10, 0.5) = C(10, 3) \\* (0.5)\\^3 \\* (0.5)\\^(10-3) = 0.11719\r  \n\r  \nNow, let's add these probabilities together to get the cumulative probability:\r  \n\r  \nP = 0.00098 + 0.00977 + 0.04395 + 0.11719 = 0.17189\r  \n\r  \nSo, the chance that Stock B is higher than Stock A after 10 years, given the specified conditions, is approximately 17.19%.", "score": 2, "replies": [{"body": "I almost want to award negative points for even asking ChatGPT.", "score": 2, "replies": []}]}, {"body": "Look man; 50/50 is another way of saying it's infinitely random and there's no way to derive meaningful risk analysis.\n\nIf you don't understand this basic principle then you have no business applying statistics to investments.\n\nSometimes I wish I could sit in on a hiring panel for a big firm and just rip them apart.", "score": 0, "replies": []}, {"body": "Why does he think that both A and B averages 10%?\n\nFirst i am little bit surprised how he calculated the expected value of B, I would calculate it as 0.3-0.1 = 0.2 = 20%, but that is wrong too.\n\nCorrect expected value is calculated 0.9 \\* 1.3 = 1.17 but that is for 2 years, for one year it is 1.085 that means the expected value for the second one is 8.5% not 10% so his statement is wrong in first case.\n\nSo the expected value after 10 years is 1.1\\^10 = 2.59 for the A and 1.085\\^10 = 2.26 for the B, but yes that tells nothing about probability.", "score": 1, "replies": [{"body": "\\> First i am little bit surprised how he calculated the expected value of B, I would calculate it as 0.3-0.1 = 0.2 = 20%, but that is wrong too.You need to weigh the outcomes by the probabilities of them happening, e.g. 0.5\\*0.3-0.5\\*0.1 = 0.1 which is correct. What you're calculating is not expected value ([https://en.wikipedia.org/wiki/Expected\\_value#Random\\_variables\\_with\\_countably\\_many\\_outcomes](https://en.wikipedia.org/wiki/Expected_value#Random_variables_with_countably_many_outcomes)) but something completely different (doesn't have a name because it's not a standard calcuation/is kind of meaningless)", "score": 1, "replies": [{"body": ">Correct expected value is calculated 0.9 \\* 1.3 = 1.17 / 2", "score": 1, "replies": [{"body": "No, your second calculation is also wrong. The expected value for two years is 1/4\\*0.9\\^2+1/2\\*1.17+1/4\\*1.3\\^2=1.21 (look at the wiki link to see how to calculate it if you don't understand right away)", "score": 1, "replies": [{"body": "to me logically two years = 1.3 \\* 0.9 = 1.17\n\nempirically though it looks like 1.1\\^2", "score": 1, "replies": []}, {"body": "why is there two times 1/4 and one times 1/2? why it isnt as i say below logically 0.9 \\* 1.3", "score": 1, "replies": []}]}]}]}]}, {"body": "Feels like it's a bad deal...but the expected return is actually still the same. If you hit 1.3 for all 10 years you get 1300% return while you only lose -65% if you hit 0.9 for all 10 years...", "score": 1, "replies": []}, {"body": "yeah man this is not an impressive solution. this is like an AP stats level problem in the context of investing. 16 year olds with scientific calculators solve this kind of shit routinely. google geometric distribution problem ap stats.", "score": 1, "replies": []}, {"body": "Congrats. You just described Bitcoin", "score": 1, "replies": []}, {"body": "I’m excited to follow you on Twitter and Reddit now", "score": 1, "replies": []}, {"body": "I re-read your post and came to the same conclusion: you're being taught a bunch of crap that won't work and you won't get anywhere with it.\n\nI really need to write a book on this because \\*this\\* is not how anything works. Black Scholes is not useful for portfolio strategy. I don't know why anyone uses it; options pricing are market derivations from supply/demand, probabilities are misused.\n\nHow to easily explain it to you who seems steeped in indoctrination of statistical analysis?\n\nAll I can think of is to re-emphasize this:\n\n* 50/50 = infinitely random and is therefore uselss\n* 100/0 = infinitely defined and is therefore priced at break even for all parties involved.\n* Somewhere in between is an unknown that is useful\n* Market forces derive this range and it's psychological and is not being quantified by anyone using Black Scholes.", "score": 0, "replies": [{"body": "Is there some way I can take the opposite side of all your trades?  I will even fill you at mid market on everything if you want.", "score": 10, "replies": []}, {"body": "You’re an idiot if you think black scholes doesn’t inform the prices the market is letting lmao.\n\nThe SVJ model is ubiquitous in the industry and is an extension of BS.", "score": 6, "replies": []}, {"body": "If not black scholes how do you determine fair price?", "score": 1, "replies": []}]}, {"body": "Check out Paul Wilmott intro to Q finance", "score": 0, "replies": []}, {"body": "It is easier to model the stocks as random variables. The probability density then fit to a distribution. I did this recently too using AI Atlss chatgpt 4 in like just few lines of code. What you just did and what you suggest is going to be redundant soon so be creative", "score": -1, "replies": []}, {"body": "consider the \"black swan\" by Taleb or Try another book on probability Schröeengers cat by Gribbon.", "score": -2, "replies": []}, {"body": "D (the last one) is what makes the most sense to me statistically but I only spent 20 seconds on this", "score": 1, "replies": []}, {"body": "In this problem, easy to see 1.1^2 >1.3*.9\n\nWe can say B can only be higher than A if it gives 30% returns for atleast 6 years. So probabilitu of giving higher returns than 6 years is\n\n= (10 C 6 + 10 C 7.... 10 C 10) / 2^10  = (210+120+45+10+1)/1024 = 386/1024  ~ 37.7%", "score": 1, "replies": []}, {"body": "Another nugget. I knew the italic part, but I hadn't seen the context framed in this way before. Neato!\n\nThe last part bolded for value to all readers on this sub.\n\n> If you price SPX index options with positively skewed model like this you will not last long.\n> \n>A positively skewed distribution says “on average I’ll make X because sometimes I’ll make multiples of X but most of the time, my lived experience is I’ll make less than X”.\n>\n> *In reality, the market imputes negative skew on the SPX options market. This shifts the peak to the right, shortens the right tail, and fattens the left tail. That implied skew says “on average I make X, I often make more than X, because occasionally I get annihilated”.*\n> \n> **It often puzzles beginning traders that adding “put skew” to a market, which feels like a “negative” sentiment, raises the value of call spreads. But that actually makes sense. A call spread is a simple over/under bet that reduces to the odds of some outcome happening. If the spot price is unchanged, and the puts become more expensive because the left tail is getting fatter, then it means the asset must be more likely to appreciate to counterbalance those 2 conditions. So of course the call spreads must be worth more.**", "score": 1, "replies": []}, {"body": "About tree fiddy", "score": 1, "replies": []}, {"body": "Fantastic post!", "score": 1, "replies": []}, {"body": "Bro this is some really serious and deep shit.One need high iq to do this?", "score": 1, "replies": []}]}
