{"title": "Tesla Full Self-Driving Beta 12.1.2 with my Dad in LA: First Impressions", "selftext": "", "id": "1ak86uh", "created_utc": 1707221037.0, "score": 17, "upvote_ratio": 0.67, "num_comments": 39, "comments": [{"body": "I hate posting this stuff because I don't want to see this stock market bubble get any worse. But full disclosure.\n\nRemember the market makers scalp the greedy. Invest with a long term horizon and don't use options or leverage. Just buy and hold. Free advice. I've seen unexpected 50%, 60%, and 70% crashes before with TSLA. It's a fun ride, but generally not for the shorts and short-term gamblers.\n\n**YouTube comment from floydb9100:**\n\n**\"**[**3:45**](https://youtu.be/7rRxW6aXGKk?t=219)  **this stop sign was performed with such perfection**\n\n[**10:36**](https://youtu.be/7rRxW6aXGKk?t=637)  **god like exit from shopping center**\n\n[**18:06**](https://youtu.be/7rRxW6aXGKk?t=1086)  **holy cow**\n\n[**20:00**](https://youtu.be/7rRxW6aXGKk?t=1195) **Good explanation to why fsd 12 works so much faster than 11**\n\n[**30:00**](https://youtu.be/7rRxW6aXGKk?t=1793) **so this is this what they meant by \"end to end\" lol ... just incredible\"**\n\n\"Highlights\n\n0:30 — Start of drive\n\n1:24 — Gate that requires creep forward to open\n\n2:00 — Unprotected left turn\n\n5:10 — Handling truck speed limit sign with lower speed\n\n8:40 — Left turn with no traffic light\n\n10:20 — Pulling into Best Buy\n\n10:40 — Start of drive 2\n\n10:44 — Navigating out of Best Buy parking lot\n\n11:25 — U-turn in parking lot\n\n11:40 — 🤯 Exiting parking lot into right turn lane\n\n14:40 — Driving up hill\n\n16:15 — Sharp left turn\n\n16:40 — Yielding where two roads merge\n\n17:26 — Dad gives his impressions\n\n17:35 — Pulling over at destination\n\n18:05 — U-turn at Cul-de-sac\n\n18:55 — Start of final drive\n\n19:49 — Slowing for dip in road\n\n20:00 — Offsetting from guy unloading truck\n\n20:40 — Slowing down for puddle in road\n\n20:52 — Car pulling into driveway\n\n21:50 — Tough unprotected left wtih long wait\n\n29:30 — Pulling into Target parking lot\n\n29:53 — 🤯 Parking at Target pick up spot\"", "score": 11, "replies": [{"body": "> this stock market bubble\n\n*cries in tsla shares*", "score": 9, "replies": []}, {"body": "Any Disengagement, Interventions, or times you were very tempted to intervene?", "score": 3, "replies": [{"body": "I'm not Omar, I'm just a fan of staying as up to date on FSD 12 as possible.\n\nBut he's had a bunch of takeovers. I posted some old content here (downvoted by the TSLAQ government bots in the daily thread):\n\n[https://www.reddit.com/r/teslainvestorsclub/comments/1aj6afy/daily\\_thread\\_february\\_05\\_2024/kp1lfi4/?context=3](https://www.reddit.com/r/teslainvestorsclub/comments/1aj6afy/daily_thread_february_05_2024/kp1lfi4/?context=3)", "score": 3, "replies": []}]}, {"body": "That right turn out of the parking lot at 11:52, where it cuts across the lanes to get into the left turn lane is awesome. FSDb 11 definitely won’t do that, as I encounter that scenario frequently.", "score": 3, "replies": []}]}, {"body": "[deleted]", "score": 11, "replies": [{"body": "Didn’t Omar have 2 hour no intervention videos on version 10?", "score": 0, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "That doesn’t tell you anything about performance. He has multiple videos for most versions. But that could just mean he has more time to make videos.\n\nTo actual measure improvement, and can’t just eyeball selective videos. We need systematic data on time between failure across a large random sample of drives. Something Musk claims has improved, but when asked to release data to back it up, he refused. \n\nThis is the company that hypes everything. They love taking simple standard off the shelf ML techniques and presenting at AI day like they invented it. If they had data actually showing progress of FSD, musk would be hyping it everywhere. Realistically, it’s stuck, and has been for a long time. And anyone with AI experience will tell you, you can’t just slap an “end to end” algorithm on the same hardware and expect improvement.", "score": 4, "replies": [{"body": "[deleted]", "score": -2, "replies": [{"body": "Oh no, the actual AI scientist showed up and crushed your dreams of magical self driving “next year”. Better start slinging the insults.", "score": 0, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Sure, my research is on distributed optimization and foundational models. Tesla and their fan base are a disservice to the field, because they constantly pump scams to try to boost their stock, while having no actual understanding of AI.", "score": -1, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "You could try asking a technical question. But of course you don’t actually know enough to do even that.", "score": 0, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Oh I have. There’s plenty you could ask about distributed optimization or foundational models. But you pretty clearly have no idea what either of those mean.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "What’s your familiarity with 3D parallelism?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Opinions on the scaling of FSDP?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Partly. How does it need to be adapted for scaling certain model architectures.\n\nBut you seem to think it wouldn’t be scalable? Any reason why?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Mostly to make you go get the first Google result for FSDP and grab a few words out of it to pretend you know what you’re talking about.", "score": 1, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "So far you’ve only given vague non-answers. Let’s try this, what model characteristics might make FSDP slow, and what other techniques might speed up training?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "So, you can’t think of an architecture that might be problematic for FSDP?", "score": 1, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "I can think of a problem that is problematic for FSDP. Neural Vision. FSD.\n\nIt will have trillions of parameters in the end and a gargantuan model. It would be incredibly slow. \n\nFSDP scales with time the more complexity and interconnections there are. Meaning wait-times for complex neural nets. Which might be fine. It's like a limit.\n\nPS. This isn't the original poster arguing with you. It's someone who tries to understand things using AI tools.", "score": 1, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "Sounds right. This makes sense because of changes in road rules, side of the road driven on, language on signs, differing lane lines, etc.", "score": 1, "replies": []}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}, {"body": "[deleted]", "score": 0, "replies": [{"body": "Sure. Of course I know you’re trolling, and like most Tesla fanbois couldn’t give a shit about actual AI. But I just find it absolutely hilarious that you losers will deny basic reality to cling to your dreams of riches from your incel emperor, and fantasies of being able to hump your waifu pillow while FSD drives you around.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Awww, that’s cute. Too bad the vast majority of SWEs know jack shit about AI.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Yeah, now you’re just making shit up. If that was the case, you’d actually be able to discuss AI on a technical level.\n\nFar more likely, you’re a recent CS grad who took an intro AI course at some point, and now thinks he’s an expert in everything.", "score": 0, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Wanna put money on that? It’s very likely V12 is actually a set of very minor tweaks (based on what Musk originally claimed end to end meant late last year).", "score": 0, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "Sorry, owning stock isn’t a bet on a specific timeline. Tesla has failed at that 8 years in a row. I’m taking about a specific bet on autonomy being delivered in the next couple years.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Again, I’m not talking about stock that’s only loosely correlated with delivery. Why not an actual bet on a specific result by a specific date? Seems like all the Tesla fans want to avoid that.", "score": 0, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Oh i do. Managed to get a few fan boys to make bets. Made some good money on earlier ones. \n\n2027? Sure. Wanna put $10k on Tesla having generalized autonomy on customers cars by that date?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Sure. But let’s get a specific definition of autonomy, so you don’t come back claiming a janky ADAS is “autonomy”. I mean a system that can operate without a legally liable driver on >90% of roads. What Musk originally sold. Something you can sleep in, rent out as a robotaxi, or put your kids in to drive them to school with nobody in the driver’s seat.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "The definition of autonomy is based on legal liability. In the sleeping scenario, who is legally liable?", "score": 1, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "Again, the definition of autonomy vs ADAS is based on legal liability. Autonomy means there is no legally liable driver.", "score": 1, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "It is. Otherwise you can call any ADAS system “autonomous”. L3 and above systems remove the liability for the driver. Otherwise, how does a car with nobody in the driver’s seat work?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Oh I’m perfectly willing to bet. But now you want to pretend an ADAS system is “autonomous”. \n\nOkay, let’s skip the actual definition of autonomy and be purely technical. A system that can complete 99.999% of all drives within its ODD without any sort of intervention. Or maybe set a MTBF floor at 500,000 miles. Does that work?", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "> where no driver attention is required\n\nAnd who is responsible for the car in that scenario?", "score": 1, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "No, I offered you another metric, since you don’t like the sae autonomy standards. 500k+ miles between interventions across the ODD on customer cars. Technically that would still be a driver aid, but we can count that as good enough.", "score": 1, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "Wait, you said a couple of years to achieve autonomy. You already tacked on another. Now you want 5 more? Wow, you really don’t believe your own bullshit.", "score": 1, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "No, I’m just setting a threshold, since you didn’t like the last one. If you think there should be a different metric, go ahead and give one. The problem with the “sleep” definition is it’s too vague. You could sleep in the current car, just not for long. So let’s use a technical specific definition, like you said you wanted, until I gave details.\n\nBut isn’t driving better than a human what this system is supposed to do? Shouldn’t that be the definition of it being complete?", "score": 2, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "Holy shit, you fucking moron. L4 is a legal definition. It’s defined by who is legally responsible for driving the car. Now you’re saying it’s unofficial? That it kinda sorta works, based on bullshit claims by the company? \n\nWhat is the standard ODD? What is considered a failure? How can it be “solved” when the standard is so far below that of a human driver?", "score": 1, "replies": [{"body": "[deleted]", "score": 0, "replies": [{"body": "There is no “equivalent” if the driver is still responsible for taking over, that’s a level 2 system.\n\nLet’s do this, I’ll take your 69,420 (even though that’s not nearly autonomous), but what counts as a failure?", "score": 1, "replies": []}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}, {"body": "I don’t believe the system is end to end neural in backprop training (like human supervised driving signals substantially update perception), but can be end to end in forward.\n\nThey did move to a more ML centric policy and planner, which was their more serious weakness.  The hard parts move from the excessive rules which couldn’t be disentangled or debugged, into the selection and balancing of the data set for policy training, which will also scale better to different locales or subtle social behavioral differences.  And I bet a substantial amount of the policy train data is still synthetic and with ideal policy coming from a conventional rules plus classical optimization based solution, but they can run that offline without the computational budget restrictions as well as not needing causality to produce the the ideal policy path. Then they could distill a neural approximator from that which can be run online.\n\nNo I don’t think they will get L4 with current sensor and computer hardware, but over time (years) it will make for a more naturally behaving high L2 product.", "score": 1, "replies": []}]}]}]}]}, {"body": "That u turn it made was pretty awesome.", "score": 2, "replies": []}]}
