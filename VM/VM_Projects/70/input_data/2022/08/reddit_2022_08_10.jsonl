{"title": "Tesla self-driving smear campaign releases test fails fsd never engaged", "selftext": "", "id": "wl2rnq", "created_utc": 1660151101.0, "score": 323, "upvote_ratio": 0.96, "num_comments": 75, "comments": [{"body": "What a silly pathetic billionaire you are Dan O'Dowd. How does one runs a company that makes vehicle safety software but can't even understand how the software of their competitor work?", "score": 137, "replies": [{"body": "Of course he understands, but he wants to make sure that everyone thinks the biggest autonomous software is a bust and dangerous and they should trust his instead.", "score": 52, "replies": [{"body": "You're giving this guy way too much credit. He's just found a way to get attention. That's it.", "score": 21, "replies": [{"body": ">You're giving this guy way too much credit.\n\nHis main business is supplying automotive software to Tesla's competitors - it's a plain old commercially motivated smear campaign.", "score": 5, "replies": []}, {"body": "Then he has a lot of common things with Elon.", "score": -23, "replies": []}]}]}]}, {"body": "No legal action? Come on Elon.", "score": 74, "replies": [{"body": "This was done for attention.  Don't give them more of what they want.", "score": 18, "replies": []}, {"body": "this calls for some streetfighting", "score": 6, "replies": [{"body": "I think we already settled on single combat instead.\n\n\nMaybe next round we'll go with streetfighting", "score": 2, "replies": []}]}]}, {"body": "This happens every single time lol. Good thing the haters are so dumb.", "score": 30, "replies": []}, {"body": "None my of Tesla hating friends have seen this ad yet. Meaning all that money spent yet it hasn't made a splash. To be fair there is a lot of FUD out there so probably will take time to make its way around the world. I'm sure I'll get pinged about it 3 months from now with them being like \"checkmate\".", "score": 24, "replies": [{"body": "It got 125k upvotes on r/damnthatsinteresting", "score": 24, "replies": [{"body": "Yea but they don't hang out on reddit or twitter. They will see it when the \"news\" (WSJ, BBC, BI, NYT) start posting articles about it I'm sure. Again my friends aren't TeslaQ but they sure do agree with them often, but I blame that mostly on misinformation coming from \"credible publications\" lol.", "score": 7, "replies": []}, {"body": "https://reddit.com/r/Damnthatsinteresting/comments/wkdh7r/tesla_absolutely_trucks_child_dummy_in_stoppage/", "score": 3, "replies": [{"body": "I love the top comments just make fun of this ðŸ¤£ ! Nobody seems outraged. \n\nLet's admit.it, we just all love see car run over stuff ðŸ¥²", "score": 2, "replies": []}]}]}, {"body": "It simply existing allows other media to assert claims that it is accurate.\n\nRandom anyone can claim something with a tweet these days and the level of journalism is such that cable/internet news will be asserting the claim as assumed truth for years.", "score": 2, "replies": []}]}, {"body": "Looks like a case for that biker gang of lawyers Tesla hired", "score": 45, "replies": []}, {"body": "I hope Tesla put those lawyers to work..", "score": 19, "replies": []}, {"body": "lol, I saw this not activated thing in video clip last night too, regarding the video resolution:\n\n1. Odd that they only uploaded it to Youtube at 480p quality that just happens to result in not being able to read the text on the screen.", "score": 17, "replies": []}, {"body": "The alert is on screen *before* the driver activates FSD. Most likely the alert is \"safety systems not available\", otherwise the car's AEB would be stopping for the child. There are about a million videos showing AEB stopping for human-shaped cardboard cut-outs. They could not make the video with either FSD Beta enabled or not. They had to pull wires to disable the safety systems as well :D  \n\nEven if I am wrong, there is clearly an alert on the screen. A warning alert with a yellow triangle. So that could be anything. So the video doesn't prove absolutely anything without knowing what this alert is.", "score": 10, "replies": [{"body": "In the 'raw' video it's one of the longer alerts, and I believe it's the 'Changing lanes away from traffic cones' warning as the car keeps attempting to move away from hitting the dummy.\n\nThe lane of cones also looks much wider than a normal lane, as if they kept making it wider and wider until it was just about 1.8 widths of the car, making it decide between two different inanimate objects to hit.\n\nAdditionally, the one time you can see the screen, the time is 5:32pm, leading me to believe they were there for hours tweaking the test to get the result they wanted.\n\nI know they have watched Beta YouTube videos and know how to make a video while capturing the screen, they chose not to for a reason. What was that reason? Where are all  the other tests? Uncut video? How many attempts? How many changes to the test methodology?", "score": 3, "replies": []}, {"body": "Donâ€™t need to pull any wires, can just disable auto braking", "score": 1, "replies": []}]}, {"body": "Oâ€˜Dowd is a peak pathetic luddite", "score": 21, "replies": []}, {"body": "LMAO imagine being that stupid that can't even smear properly. Let's get the litigation team rolling", "score": 7, "replies": []}, {"body": "Interesting.  Can't event comments on his video on YouTube.  Wonder why.\n\nIt still passed me off that YouTube won't let public see how many dislikes on a video.  I guess YouTube feel someone's feeling might get hurt if there is too many dislikes?", "score": 7, "replies": [{"body": "Donâ€™t dislike misinformation there. It counts as engagement.", "score": 4, "replies": [{"body": "Personally if I see a lot of dislikes, I wouldn't go view it.  Any viewing of the video would give them money.\n\nJust saw the same ads on TV minutes ago on one of national stations.", "score": 2, "replies": [{"body": "YouTube removing visible dislikes was a huge negative to the platform. It used to be much easier to spot scam content.", "score": 2, "replies": []}]}]}]}, {"body": "His account has only 49 subscribers ðŸ˜‚ I want to see tesla legal team take this guy down to his knees on one of his ads.", "score": 4, "replies": []}, {"body": "This is the epitome of naysayers and laggards wasting money on advertising. Dan even took out a full page ad in the NYT.", "score": 3, "replies": [{"body": "I saw it as TV ad last night. This is in the San Francisco market.", "score": 5, "replies": [{"body": "He ran the ad several months agoâ€¦I think it was teasing this â€œstudyâ€. The whole thing is carefully crafted and intentionally deceptive.", "score": 1, "replies": []}]}]}, {"body": "Do I need to purchase $12k FSD to have pedestrian avoidance available? I thought that safety feature was already included?", "score": 0, "replies": [{"body": "Standard Safety Features\nThe following standard safety features will continue to be active on all new cars.\nAutomatic Emergency Braking\n\nDesigned to detect objects that the car may impact and applies the brakes accordingly\nSide Collision Warning\n\nWarns the driver of potential collisions with obstacles alongside the car\nFront Collision Warning\n\nHelps warn of impending collisions with slower moving or stationary cars\nAuto High Beams\n\nAdjusts high/low beams as required", "score": 5, "replies": []}, {"body": "Keep your eyes peeled and your hands on the wheel until told otherwise and you will be okay.", "score": 1, "replies": []}]}, {"body": "The driver provided a sworn afidevit that they beleived FSD was activated.  Being able to tell that a vehicle is in self-driving mode is a critical element of that system's safety.  The fact that the Electrek article is complaining that they can't read the small text on the screen to determine if FSD is on isn't a great look.  If a driver attempts to start FSD, but FSD does not start, it should be glaringly obvious to the driver.", "score": -6, "replies": [{"body": "It is obvious.", "score": 7, "replies": []}, {"body": "It is glaringly obviousâ€¦which is why everybody can tell this â€œtestâ€ is a complete fraud.", "score": 4, "replies": []}]}, {"body": "I say this technology needs to work without being enabled first, until then its too unsafe for the public!", "score": -7, "replies": [{"body": "As you can see there is an yellow warning pop up on the screen. Offcourse the video is shot in 480p quality so we can't read what it says. Most likely scenario they've messed with the car to get these results.", "score": 2, "replies": []}]}, {"body": "About fucking time, the entire premise for the autopilot is stupid and not worth the risk to the human lives. Our tech is simply not there for safe auto pilot, not until lidar becomes more common place and cheaper.", "score": -41, "replies": [{"body": " Correct, we need to bring back the horse and buggy.  Things were much safer then!", "score": 17, "replies": [{"body": "Horses were crazy dangerous. And a massive public health menace.", "score": 2, "replies": []}, {"body": "Nah, no need to paint me as a luddite, in fact I do software development for law enforcement agencies around the US. It's a challenge for computers to identify objects in images, for many reasons, anyone who claims otherwise is a Liar. Now, I have no problem with the idea of the Autopilot but I hate how it's being implemented. Every company is out doing their own shit but if we actually want our cars to Autopilot it needs to be a government driven program that establishes some priorities, for example: should the AI prioritize the safety of its passengers or pedestrians? There are many things that need to be regulated about the Autopilot, another example the fact that you can set Tesla to blow past stop signs is fucking ridiculous.", "score": -18, "replies": [{"body": "[deleted]", "score": 13, "replies": [{"body": "This thread has a misleading title but sure shows just how shit tesla video detection is:https://old.reddit.com/r/Ghosts/comments/wkxudz/car_with_lidar_technology_appears_to_make/", "score": -1, "replies": [{"body": "[deleted]", "score": 4, "replies": [{"body": "No shit its beta software, that is exactly my point. We have to test our 911 emergency response software through and through so that our company does not get sued for wrongful death. And that is software in the capable hands of dispatchers who have experience dealing with highly stressful scenarios. But Tesla gets to fucking test their software on the roads? In live conditions? With no oversight? Get the fuck out.", "score": 1, "replies": []}]}]}, {"body": "Yes ,the FSD is so superb this NEVER happens:https://www.google.com/amp/s/www.republicworld.com/amp/entertainment-news/whats-viral/teslas-full-self-driving-autopilot-feature-mistakes-moon-for-yellow-traffic-light-watch.html", "score": -4, "replies": [{"body": "[deleted]", "score": 6, "replies": [{"body": "Ugh, I fucking hate people who claim that black box AI is the way to go. Good fucking luck fixing the code if your AI fucking kills a human being.  Better luck training a new CNN but then again nothing guarantees that the new CNNn will handle all of the real life edge cases on the road. Fuck off you computer ignorant troll", "score": -6, "replies": [{"body": "[deleted]", "score": 4, "replies": [{"body": "He perma gone.", "score": 4, "replies": []}]}, {"body": "Another rule violation.", "score": 3, "replies": []}, {"body": "so pease tell us how you want to code every edge case by hand?\n\neven how you identifiy every edge case?\n\nsooner or later fsd will kill someone, its only a matter of enough fsd cars and time. But, if fsd has a way lower death rate that the average human driver, shold we ban this technology until it is ... how good exactly?\n\nwhere is the threshold at which we allow deaths by a machine to occur and by which factor must the machine be safer than a human?", "score": 1, "replies": []}]}]}]}, {"body": "Lol, the fact he has to claim he works in software development to try and achieve a level of authority instead of sticking to the issue and simply reasoning it out by explaining the actual facts and detailed workings of the topic at hand makes it seem like another â€œinternet educated expertâ€ rather than someone who actually works in the field. Also software developers working for government arenâ€™t exactly the leaders in technological advancements, more likely just using, fixing and maintaining software bought from a third party.", "score": 1, "replies": []}]}, {"body": "There is no setting to blow past stop signs, but I know my truck with cruse control will do it every time!  \n\nPS there used to be a setting for rolling stop at like 2-5 mph if the intersection was clear just like most drivers do. They took that away some time ago.", "score": 5, "replies": [{"body": "Fair enough, but the fact that they even had that option means we need more regulation in the sector.", "score": -9, "replies": []}]}, {"body": "This is misinformation.", "score": 4, "replies": []}, {"body": "I don't know why you're being downvoted. There are so many pedestrian deaths already in the US due to car centric infrastructure. Idiots misusing tech is a serious risk to making that death statistic worse.", "score": 1, "replies": [{"body": "I am getting down voted because people don't like being told that they just spent 90k on a brand new car whose auto drive feature is complete shit.", "score": 1, "replies": [{"body": "Yeah I think automakers should focus on highways only and reduce complexity/edge cases.\n\nI'm based in Europe and by the time there is any semblance of L3 self driving, our main cities will have gone largely car-free. I live in Amsterdam and it will never work here, and it's also a solution to a problem that doesn't exist.", "score": -1, "replies": []}]}]}, {"body": ">it needs to be a government driven program\n\nSounds like a guarantee that it will suffer massive cost overruns and never, ever work properly.\n\nAlso, code written for governments tends to be buggier because of the incentive and payment structure: [https://www.forbes.com/sites/andygreenberg/2012/03/13/study-confirms-governments-produce-the-buggiest-software/](https://www.forbes.com/sites/andygreenberg/2012/03/13/study-confirms-governments-produce-the-buggiest-software/)", "score": 1, "replies": []}, {"body": ">should the AI prioritize the safety of its passengers or pedestrians\n\nThat question strikes me as a red herring. Human drivers aren't prioritizing the \"correct\" thing in this case. I don't think any driving school teaches new drivers which to prioritize. And even if they did, there's no enforcement mechanism.\n\nHuman drivers might be randomly choosing whether to prioritize passengers or pedestrians. Or they might be prioritizing themselves due to their own self-interest. Either way, human drivers are most certainly not engaging in some scrupulous, detailed calculation of the merits of one priority versus another.\n\nIt's absurd and unfair to hold self-driving cars to a higher standard than human drivers. Given that human drivers are not engaging in any kind of rational or deliberate or ethical calculation on this subject, it's hypocritical to say that self-driving cars must engage in some particular ethical calculation.\n\nI say, as long as self-driving cars are at least as good as humans, then they are acceptable. They shouldn't have to be better than humans.", "score": 1, "replies": []}]}]}, {"body": "In case you're not trolling: you know this how? Have you seen recent beta fsd runs on YouTube?\nWhy would lidar help? It can't read roadsigns, it's low resolution, it can't handle snowfall, and so you still need optical, which is already proven capable of seeing 3d through time.", "score": 8, "replies": [{"body": "You mean the same optical sensors that read a super moon in Colorado as either a yellow or red light? Those awesome things? And no, the optics do not see in 3d, they just use multiple cameras to capture same image from different angles and the computer still has to process both images. Just like the computer would have to process thousands of lidar scans. Also note, I never said that they will have to do away with the optic cameras, those are still needed on top of the lidar.", "score": 1, "replies": [{"body": "Look at the AI day video - Karpathy shows how video of driving through a street is converted to vector space.\n\nWhen you move towards something, the relative positions of everything change in your view. This is enough information to make things 3d.\n\nMaybe lidar could make it better, but if lidar and optical disagree, which one is the correct one?", "score": 4, "replies": [{"body": "Too bad the guy quit", "score": 1, "replies": [{"body": "Yeah, I wonder what the impact will be but seeing the progress in fsd beta I'm guessing they set up a great team.", "score": 1, "replies": []}]}]}, {"body": ">\tmultiple cameras to capture same image from different angles\n\nYou just described stereoscopic photography which is how 3D cameras work,", "score": 1, "replies": []}]}]}, {"body": "Already safer in highways than an average driver.... autopilot has caused fewer accidents in a Tesla when used than when not used. The data is quite clear: The average human is not a better driver than autopilot but because the technology can cause deaths while in reality saving more lives, it will be looked at negatively. Meanwhile, some drunk driver who runs red lights is supposed to be more responsible? Give me a break. FSD has and will have its issues but it will be lifechanging. It will reduce congestion, increase productivity, and make traveling a breeze.", "score": 6, "replies": [{"body": "The only real way to reduce congestion is to build better cycling infrastructure and better public transportation. Rush hour traffic is a thing that self driving cars won't solve.", "score": -2, "replies": []}, {"body": "Of course the average human lacks the reaction time that the computers are capable of these days but you know what we have? 16 to 18 years of life experience that allows us to understand, analyze and adjust to edge cases. That is where the problem will be for the auto pilot, edge cases, ability to recognize that a road flare might mean that there is an accident or congestion ahead. \n\nAgain. My point here is not that we should abandon progress but that it needs to be studied and regulated properly.", "score": 1, "replies": []}]}]}, {"body": "I knew it", "score": 1, "replies": []}, {"body": "Such BS. Please sue.", "score": 1, "replies": []}, {"body": "If he really thinks Telsa FSD is dangerous why not offer your expertise on how to fix it (assuming it's broken)? Why go straight to trying to destroy it altogether? Dude is just out for himself.", "score": 1, "replies": [{"body": "Becouse he's a competitor.", "score": 2, "replies": []}]}, {"body": "Even without FSD, shouldn't automatic emergency braking have activated?\r  \n\r  \nMost new cars today have automatic emergency braking (AEB) even if they don't have \"self-driving\" (sic) capability. Often, the AEB can be deactivated if the owner digs deep enough in the menus, but at least by default, AEB is on and doesn't have to be activated.\r  \n\r  \nSo there's still something wrong with the Tesla if passively failing to enable FSD is equivalent to actively disabling AEB.", "score": 1, "replies": []}]}
