{"title": "How important are the \"normal\" cores in an AI workload? Do AI-specific chips like Microsoft's actually threaten Nvidia's business?", "selftext": "Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads.\n\nWhile I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple.\n\nWhat I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer?\n\nI don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs.\n\nNote: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.", "id": "181smem", "created_utc": 1700712837.0, "score": 27, "upvote_ratio": 0.8, "num_comments": 37, "comments": [{"body": "Google has 5 generations of TPUs. Half of Google runs on TPUs. Bard and GSE with 200+ million monthly users runs on TPUv5e \n\nIs Nvidia being put out of business by Google? Amazon has its own AI accelerator. Is it stealing business? \n\nNo. Because Nvidia is more than a CUDA core. \n\nIn 5-10 years however, I expect the mega cloud companies to put as much of their own hardware in as possible to prevent being monopolized by a single company. They also will fund AMD as an alternative. Nvidia isn’t a true monopoly.", "score": 37, "replies": [{"body": "While Google are the clear leaders with TPUs AWS has Trainium and Inferentia, Azure has Athena.\n\nASICs will be the way forward as training runs and inference loads scale up the cost to design and tape out a chip will easily be justified by the huge savings in overall compute costs.\n\nIt's quite possible in the future we get ASICs specialized for a particular model's training run / inference workload - think the GPT6 / Gemini 2 / cloooong chip that has a hardware made to support that particular memory profile.\n\nNvidia will still have a huge role in more general purpose tasks, but I doubt the hyperscalers and frontier labs will be reliant on them in 3 years.", "score": 4, "replies": []}, {"body": "5-10 years in the future means post singularity and these companies won’t be recognizable from what they are now.", "score": 2, "replies": []}, {"body": "Can you elaborate on why Google doesn't try to compete with Nvidia when tpuv5s are faster and more cost effective than a100s? Why wouldn't google try to compete in the ML chip space when they have such a good product line?", "score": 2, "replies": [{"body": "Google make hardware to be independent from Nvidia, why would others buy Google's instead of making their own instead? The hyperscalers have resource to design their own chips, while small player buy Nvidia because CUDA is tried and true, while Google's is internal project so external support is limited/not worth while to bet on.", "score": 4, "replies": []}, {"body": "They do, but they sell compute not hardware. You don't buy a TPU you rent a TPU cluster.\n\nThey are already a hyperscaler running data centres so no need for another middleman taking part of the profits.\n\nhttps://cloud.google.com/tpu/pricing/?gad_source=1&gclid=CjwKCAiAjfyqBhAsEiwA-UdzJJ4_ylj9gAv_tLtngmvZGg1oYlXZ_FBAXuwoh8T6dLxJzFgtuwUkiRoC2owQAvD_BwE&gclsrc=aw.ds", "score": 3, "replies": []}, {"body": "They have an internal cloud hosting platform that they use for their own apps. Instead of finding a way to provide their own internal cloud hosting capabilities to external customers, they decided to take years to build out their own external Google Cloud. Forgoing the massive market share they could have garnered by having superior cloud offering available much earlier. Why would they do this, aside from managerial/organizational incompetence? Hard to say", "score": 1, "replies": []}]}]}, {"body": "It will take a pretty long time to happen, IMO.  But I do think over time the chips will move more and more to the Googles of the world.\n\nI am old.  Really old.  So it is pretty interesting to watch.   We started with the chips coming from the companies that made the machines.  The DECs, IBMs, HPs, etc.\n\nThen we moved to third party.   But now we are moving back to the old way.\n\nApple is already there for their phones and now laptops.   Google is also there for their phones.  But also for their cloud with the TPUs.\n\nMicrosoft is late and not sure what took so long to get it. But now they are doing the same.\n\nI do not see it changing.  But NVDA will be fine for a good length of time and I would not worry about it too much today.", "score": 5, "replies": [{"body": "You mentioned IBM, but I think it is safe to say that IBM still sells their powerpc based systems and even new supercomputers with power architecture are coming up.", "score": 1, "replies": []}]}, {"body": "The first thing to note here is that the compute cost of inference is dropping all the time. Once trained models can be made to run more efficiently. For example, I can run LLaMA 2 locally on my Macbook and it runs great. The world doesn't necessarily need GPUs in a world where the best AI models can run on consumer hardware.\n\nReally the only place where NVDA is needed right now is in data centers for training and I'd guess the main long-term priority there will be cost. Even if NVDA has the best GPUs it doesn't necessarily mean you're going to get the best bang for your buck with NVDA. If other competitors have something decent enough so long as they're priced attractively they'll begin to take market share from NVDA.\n\nI think if you're bullish NVDA you basically have to assume that NVDA's CUDA software is so much better and so well liked by developers that companies will be willing to pay a premium just to use it. And I think that will happen to some degree, but again you'd think there will be a point at which the cost to retrain devs to use some other software is going to look attractive...\n\nFor me it just keeps coming back to the fact that it's very hard to maintain pricing power when the long-term moat appears to mostly be cost.\n\nFor now NVDA is basically the only game in town and every company wants to get into the AI hype so they're going to buy NVDA GPUs whatever the price, but I think slowly you'll see competitors and developers start looking to cheaper alternatives. And as that adoption of alternatives increase that's probably when the market will reprice the long-term growth and margin story. Maybe that's not for a few years yet, but I'd be amazed if it isn't coming.", "score": 5, "replies": []}, {"body": "I am going to point this out again, If AI becomes actual gold, every company will make their own chip/AI. Most likely AI will be the next thing, who would ever want their progress hamstrung by another company if the race to make the best ensured domination of that space?", "score": 6, "replies": [{"body": "I'm thinking more along the lines of, where will all the companies that actually can't allocate the capex needed to have their own chips go? Microsoft/Amazon/Google/etc will obviously have their own architectures, but if they're all making vendor-locked architectures it means some cross-party middleware/software stack will gain importance as these companies not creating their own chips will be signing deals with the hardware providers to integrate their solutions.\n\nThen it just becomes a question of performance, space and power efficiency. Even space to some extent is irrelevant to these companies because they don't care about the physical layout of the datacentre as much as they care about 99.9999999% uptime reliability. Then it just becomes a matter of performance:cost.\n\nGoogle and Nvidia are both capable hardware-wise of being the dominant architectures but obviously the software stack is currently heavily in Nvidia's favour in terms of public availability and ecosystem.", "score": 2, "replies": [{"body": "They will still buy from Nividia, but they are small gains, or at Nividia's growth targets, worthless gains. They will still make money, but no where near the current demand.   \n\n\nNividia is gold right now, because they are selling the shovels to mine the gold to everyone. If the people mining the gold start making their own shovels, then they are fucked. All the companies that do not have the capex will still buy, but they are less than 5%-10%. Most of Nividia's gains are coming from the whales. The dolphins and normal companies will still buy, but man if Apple/Google/Amazon ect.... make their own, a lot of their growth market disappears. China/India are also going to try and do their own thing.   \n\n\nAgain who knows though honestly.", "score": 1, "replies": [{"body": "I'm a huge nvda bull, but I recognize this as a genuine risk.\n\nI take comfort that even their direct lifetime rival AMD has not been able to do what the hyperscalers are attempting. Not to mention nvda has been compounding using their own AI tech to help design the chips.\n\nIt would be untenable for the hyperscalers to not be making their own chips - but I imagine their own chips will be mostly leveraged for their own worklows (like copilot on azure, and all the other AI enterprise offerings they will have), while the cutting edge research could still be limited to more generically powerful chips like NVDA.\n\nI need to learn more, but I would say there is a reason NVDA was positioned to both deliver and capitalize on the AI moment, and that while everyone can now see this is valuable and the way of the future, I do not think it will be so easy for anyone to replicate on short order. And you have to compete against the rate of improvement, not against whatever performance the chips have now.\n\n\nBut I agree - no one truly knows. It is an evolving situation that deserves close attention.", "score": 1, "replies": []}]}]}, {"body": "They’ll all be hamstrung by tsm tho", "score": 3, "replies": [{"body": "That’s contingent on whatever happens in China (either politics or industry competition)", "score": 1, "replies": []}, {"body": "doesnt china have 7nm technology ?", "score": 1, "replies": []}]}, {"body": "> If AI becomes actual gold, every company will make their own chip/AI.\n\nHow long will it take to catch up? Since it's a field where you always want the very best to be competitive.", "score": 1, "replies": [{"body": "That depends on what the AI needs to do. If it is do everything, like a jack of all trades literally, it will take a long time. If it is specific (which we are already seeing with modules, not very long). AGI or do everything will be quite a ways off and unusable at at consumer scale (not understanding how to use it to get what they want), but AI that is focused on lets say Investment, Military, Urban planning ect... much more focused and much easier to focus use as a Human.\n\nAnother way to look at it, look at what people are spamming forms with, the most basic stuff, repeated endlessly and each thinks they are unique. Very few outliers that have done more than the bare bones in challenging the AI and what would come out of the AI. I think a general every day use AI is not going to take long to come to market as a Siri/personal AI, specialized AI will be behind gov/companies door and indie open sourced will be fast as well. But all in one, very long, but we don't need that for a long time.\n\nA lot of AI is currently built off just a few players, with everyone else finding niche's or pieces of that pie and selling it as a business charging for the API.", "score": 1, "replies": []}]}, {"body": "Exactly this. If you’re a service offering and you charge $1, NVDA takes $.80. No company will allow the hardware part of the supply chain to eat up that much margin. They’d rather not put out a service until prices come down.", "score": 1, "replies": []}]}, {"body": "Nvidia is going to keep dominating the market for training chips. But inference is considered to be a more important growth market, and there is a lot more competition there.", "score": 2, "replies": [{"body": "Can you help me understand why Google or Microsoft cannot win the training market?\n\nInference as I understand it is simply applying input not provided in the training data to receive an output which is (hopefully) correct, so that becomes the application side of things.\n\nHowever, aren't the companies actually creating trained networks more likely to make bucket-loads of cash because application-side businesses will be wanting to buy those networks and a lot of it may not be provided exclusively to any one business?", "score": 2, "replies": []}]}, {"body": "I think if the underlying computational structure of the field doesn’t change at all ASICs are pretty strong\n\nBut AI is rapidly changing, little is known about even the model underlying the chatbots, its only a few years old.  NVDA pushed out an update to its chips that doubled their speed a month ago by changing the way they process AI loads.\n\nWhat if a completely different computational model is better? Do the ASICs become worthless? \n\nSo, as long as things keep changing more general processors are king.\n\nAlso as a practical matter, the amount of compute necessary to run all of GOOG search traffic through chat bots is orders of magnitude greater than what they have now, which is why they haven’t pushed it out broadly and why MSFT could (because Bing has orders of magnitude lower market share)\n\nSo the amount of compute available over the next few years is going to have to grow by orders of magnitude, which if NVDA gets a small piece even is huge.", "score": 2, "replies": []}, {"body": "I would be scared as hell of Next Silicon if I was any of these large GPU/accelerator companies.", "score": 2, "replies": []}, {"body": "In a few years each big player will have data centers built with their custom hardware... Intel and tsmc will be the foundaries... Paper designers like nvda and amd will slowly decline", "score": 3, "replies": [{"body": "More likely Samsung and TSMC, but who knows - IFS uptake hasn't been that rapid so far.", "score": -2, "replies": []}]}, {"body": "CUDA is more than hardware, it is also back end software API on which algorithms are built\n\nIn house Goog Amazon or MSFT chips mean inhouse I e. No body else uses them outside this company for research development or product etc\n\nThis means that nobody outside these companies learn to use them\n\nThis means that smaller companies go for technology that is relatively open source for which the hardware is Nvidia unfortunately\n\nIf Goog Amazon Microsoft etc want to sell their hardware, they need to embrace open source use of their backend software API e.g introducing in tensor flow the backend API for their software, supporting different devices etc\n\nSee examples: Intel mkl Open CL CUDA etc\n\nIn summary, you have to provide the software drivers available outside your company in open source for your hardware development to make sense", "score": 2, "replies": [{"body": "While the CUDA ecosystem is strong, that is more because of what is built on top of CUDA.\n\nThe knowledge pool behind those applications can definitely transition to some other platform especially if it is supported on multiple hardware architectures if it reduces their dependence on Nvidia and the economics makes sense.\n\nSo there might be a gradual competing snowball but Nvidia could remain a juggernaut.", "score": 3, "replies": []}, {"body": "Total BS.  Google (TPU) and AWS (Inferentia) AI hardware is available for public use.\n\nhttps://cloud.google.com/tpu\n\nhttps://aws.amazon.com/machine-learning/inferentia/", "score": 6, "replies": [{"body": "How many computers have you bought in the last 2 years that contain a TPU? Or inferentia or whatever it is you call it\n\nLike I said, if you make a highly specialized equipment tailored to your organization, don't be surprised if others don't adopt it as a standard\n\nOpen source and Open API is the key", "score": 3, "replies": [{"body": "These organisations rent the resources on AWS or some other platform. AI developers dont want the added headache of full stack datacentre management unless they already have existing datacentre businesses.", "score": 5, "replies": []}]}]}, {"body": "If  i am building a huge model, i 'd be willing to spend a few weeks to change my libraries to use a non-cuda API , since the training of the model will take months anyway and will be the bulk of the cost. it s inevitable that cuda competitors will catch up. and surely we will end up with an open source standard for them", "score": 2, "replies": [{"body": "There already is open source it’s called RISC-V", "score": 1, "replies": []}]}]}, {"body": "we should expect tensor cores to become dirt cheap in the next 2 years. someone will make an open source design to offload 90% of inference computation (training only needs to happen once), and ultimately the edge will be dictated by cheap electricity, like they did with crypto.\n\nwhere is cheap electricity? iceland/russia/china?\n\nAnd then we may have have completely new technologies like physical deep networks that use physics principles to run deep networks. This may completely upend the field\n\nhttps://www.nature.com/articles/s41586-021-04223-6", "score": 1, "replies": [{"body": "Is the L40s geared more towards the inference projects than towards training?\n\nYou say open source design for inference offload, but actually constructing the silicon requires a lot more work and with more packing efficiency being demanded every year, and Moore's law's limits being tested at the atomic level year after year, I wonder how many companies will be willing to simply copy and paste some open source design into their silicon and then simply tweak it.", "score": 1, "replies": [{"body": "but you wouldnt need the highest-end chip fabrication for these machines. they are not power-constrained like mobile phones and laptops. china will probably make tons of them with whatever lithography machines are available", "score": 1, "replies": []}]}]}]}
{"title": "Tesla 🇨🇳 officially indicated today the prep work to roll out FSD Beta is “currently underway” in response to reporter’s inquiry. Though no specific timeline is given, I’m guessing it’ll be when V12 is ready, probably towards the end of December or early January 2024.", "selftext": "", "id": "182dlf1", "created_utc": 1700781164.0, "score": 61, "upvote_ratio": 0.79, "num_comments": 29, "comments": [{"body": "I’m bullish on Tesla, but prep-work is always under way.   FSD has to be safe enough to release, at any point a potential release can be stopped if the new release is deemed less safe than what it is replacing.", "score": 8, "replies": []}, {"body": "Is it a robotaxi yet", "score": 5, "replies": []}, {"body": "2 weeks…", "score": 8, "replies": [{"body": "[removed]", "score": 3, "replies": []}]}, {"body": "I doubt it’s v12 though.", "score": 7, "replies": [{"body": "[deleted]", "score": 8, "replies": [{"body": "I hope it’s v12 for sure. I’m just not getting the feeling that it’s imminent. Plus Elon said v12 would be delayed for 6 months for HW4. Lots of hardware 4 in china.", "score": 2, "replies": [{"body": "They could still release it on HW3 first.", "score": 2, "replies": [{"body": "That would explain why v12 would still be \"beta\" . They are waiting on v12 on hw4 to \"officially\" exit beta. Semantics really", "score": 3, "replies": []}]}]}, {"body": "So they don’t get sued by every car they sold with fsd…. Literally the only reason", "score": -2, "replies": []}]}]}, {"body": "while US media is desperately trying to trash & troll Tesla, an American company -China is embracing it-what a juxtapose world.", "score": 1, "replies": [{"body": "Embracing it? You are being delusional. Tesla cannot enter anywhere near government building. And Teslas are constantly pulled over  on the road when “important” event is going on.", "score": 3, "replies": [{"body": "Not true.  Teslas can now operate on government property.  Your info is out of date.", "score": 6, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "In the news.  It occurred the day after Elon met with Xi on his visit.  Don’t you know know how to Google?", "score": 2, "replies": [{"body": "[deleted]", "score": 1, "replies": [{"body": "He is only being delusional", "score": 1, "replies": []}]}, {"body": "If you are referring to [this news](https://www.rfa.org/mandarin/yataibaodao/zhengzhi) it explicitly said government only “demolish the public sign that restricting Tesla from entering” but “no sign of actually relieving the restriction”", "score": 1, "replies": [{"body": "It looks like you shared an AMP link. These should load faster, but AMP is controversial because of [concerns over privacy and the Open Web](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot).\n\nMaybe check out **the canonical page** instead: **[https://www.rfa.org/mandarin/yataibaodao/zhengzhi/gt2-11232023014941.html](https://www.rfa.org/mandarin/yataibaodao/zhengzhi/gt2-11232023014941.html)**\n\n*****\n\n ^(I'm a bot | )[^(Why & About)](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot)^( | )[^(Summon: u/AmputatorBot)](https://www.reddit.com/r/AmputatorBot/comments/cchly3/you_can_now_summon_amputatorbot/)", "score": 1, "replies": []}]}]}]}]}]}, {"body": "China actually embraces science and engineering while US has gone woke to broke and is too busy \"decolonizing\" stem and removing algebra from school curriculums for being \"racist\"", "score": -7, "replies": [{"body": "What the hell are you talking about.  You are either some kind of China simp/bot or completely out of your mind.", "score": 12, "replies": [{"body": "Lol. Says the brain dead TSLAQ loser\n\nhttps://fordhaminstitute.org/national/commentary/algebra-none-effects-san-franciscos-de-tracking-reform", "score": -3, "replies": []}]}, {"body": "lol yeah, all those geniuses and higher test scores from the rural and conservative regions of the country.", "score": 0, "replies": []}, {"body": "They have little care for pedestrians is what you were going for here.", "score": 0, "replies": []}, {"body": "Definitely a China bot. Most of China’s “advancements” in tech are superficial and stolen from other companies. They are the leader when it’s comes to manufacturing though but any leading green/EV initiatives are a complete farce", "score": 0, "replies": []}]}]}, {"body": "In between V12 and the ensuring worldwide FSD rollout, and China in particular along with a good earnings release in January 24 TSLA will be a $2T company before end of q1 24.", "score": 0, "replies": [{"body": "😂. Margins unfortunately are going to be too low to ensure a blowout q4, let alone 2023 year end financials. I’d love to see the share price increase 150% but that’s just so, so unlikely given the reality of Tesla’s current sales operations.", "score": 5, "replies": []}, {"body": "hopefully not that early, need more time to accumulate!!", "score": 2, "replies": []}, {"body": "Lol", "score": 1, "replies": []}]}, {"body": "Big if true", "score": 0, "replies": []}, {"body": "Can't wait for my appreciating investment to start doing taxi trips while I sleep.", "score": 1, "replies": []}]}
