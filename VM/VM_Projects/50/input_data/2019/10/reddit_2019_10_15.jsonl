{"title": "Thoughts on NVDA long term?", "selftext": "Currently holding shares I bought @ 145 which means I'm up over 30%. The stock has been really volatile the past year and I can't see it reaching it's all time high soon because that was mostly due to the crypto craze. I am thinking of selling it all and enjoying the little profits but would appreciate any thoughts or ideas.", "id": "di8khw", "created_utc": 1571149178.0, "score": 45, "upvote_ratio": 0.86, "num_comments": 48, "comments": [{"body": "Gaming, ai, chip, and autonomous driving, you got all the good revenue drivers, hold it.", "score": 39, "replies": [{"body": "AI industry is expected to grow to ≈$79B by 2022, increasing by ~38%/year supposedly.", "score": 8, "replies": [{"body": "This is already priced in. So to outperform the market it needs to do even better.", "score": 8, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "How would it not be? Is it a secret?", "score": 2, "replies": [{"body": "[deleted]", "score": 2, "replies": [{"body": "That is fundamental to the efficient market theory, care to explain why you think it would not be priced in?\n\nWhy is Amazon’s P/E so much higher than Best Buy’s? Because it’s assumed that it’ll grow far more. Same applies to all industries.", "score": 1, "replies": []}]}]}]}]}, {"body": "what AI stocks are there to buy?", "score": 1, "replies": [{"body": "Unfortunately a lot of the companies specifically working on just AI development aren't public (happy to be corrected if someone knows of some) but bigger corporations like $NVDA, $IBM and $INTC. There's an ETF called $BOTZ that's robotics and AI as well. \n \n$INTC and $IBM are also putting a lot of money into quantum computers which having refined systems with public use cases are probably less than a decade off, might be something to keep an eye out for.", "score": 1, "replies": []}, {"body": "Unfortunately a lot of the companies specifically working on just AI development aren't public (happy to be corrected if someone knows of some) but bigger corporations like $NVDA, $IBM and $INTC. There's an ETF called $BOTZ that's robotics and AI as well. \n \n$INTC and $IBM are also putting a lot of money into quantum computers which having refined systems with public use cases are probably less than a decade off, might be something to keep an eye out for.", "score": 1, "replies": []}]}]}, {"body": "all that plus AR and VR", "score": 1, "replies": []}, {"body": "Yeah I agree...not to mention that the crypto driver isn’t in play currently, but it will be again soon imo\n\nAlso, from a technical perspective they just broke out of a big consolidation phase with their price move today. Assuming the overall market can stay strong I think there’s no reason why they don’t push towards highs again", "score": 0, "replies": []}]}, {"body": "I would be skeptical,\n\nFirst let’s look a little at the current Turing architecture on the market. Turing is Nvidia’s current architecture, and by all means it is a good architecture. However there are two notable flaws with it. Raytracing and tensor cores. Raytracing and the fix function hardware associated with it (here by referred to as RT cores) was a very poor implementation of raytracing as it attempted to combined it with rasterization meaning that it is path-tracing and not raytracing. The issue with this is that there are currently not enough RT cores to perform the calculations for pathtracing, meaning that the shader unites are bottlenecked by the RT cores so we observe a massive decrease in performance. With the next launch of Nvidia cards (not the refreshes), I would guess there would be at least a doubling in RT cores, however the primary issue with this is that their implementation of raytracing will be obsolete because of consoles. The next generation of consoles which are powered by an AMD apu will have raytracing, however the hardware will not be fix function, furthermore, it will be an open standard similar to DX12 meaning that vastly more games will be able to easily implement raytracing. This is a major issue with Nvidia because their hardware will not be as well optimized for these games, meaning lower performance. Furthermore, because they touted raytracing as their new schtick they cannot remove it the following generation as that would be admiring defeat, causing backlash in stock prices. Tensor cores for the most part are never used unless upsampling or for very specific rendering tasks, so on consumer GPUs, they are never used. These two factors have lead to Nvidia having enormous die areas, for example, the 2070 super has a die area in excess of 520mm2. When we compare this to what the die are of AMD’s Navi GPUs, we see that they are a little less that half the size at roughly 250mm2, this means that even taking into account the node shrink, the Navi GPUs are roughly 30% smaller. Smaller die sizes are much cheaper as yield are better, meaning that they can have a larger profit margin at a lower price. Furthermore, Nvidia dig themselves into an even deeper hole with the ludicrous 1200$ MSRP of the 2080ti. This astronomical price lets AMD scale their GPUs up to 650mm2, handily beating Nvidia, and even put on HBM2E memory to add more efficiency and more bandwidth becomes a possibility. Nvidia’s compute cards are not looking good either because they are so expensive that companies are starting to simply make their own ASICs (ei: Tesla) or turning to AMD with their Vega solutions. Vega is a very good computer card, and with not getting into too much detail about how the architecture works, we could see a Vega card with 128 compute unites, twice as much are Vega frontier cards.\n\nAMD is not Nvidia’s biggest threat though. Intel is. Currently intel is getting dominated in the CPU space, and will not make a proper recovery until earliest 2021 (with current timelines and leaks). However, they recently spent 18b on consumer GPUs. To give some context, Turing costed roughly a billion over the course of 5 years. Intel just spent 18x that amount and they have some very smart people, meaning that their GPUs will be monsters in terms of efficiency. Not too many details are known about the Intel SKUs, however when we look at some of their earlier APUs, we see that even when Intel was not focusing on GPUs, they made incredible chips as seen in Ivy-bridge.\n\nThat's just my two cents of what we could see with NVIDIA, I simplified a lot of aspects of their architecture and what Intel and AMD have.", "score": 31, "replies": [{"body": "holy shit, this guy wrote a god damn book", "score": 14, "replies": []}, {"body": "So do you think Intel is undervalued?", "score": 3, "replies": [{"body": "Not right now, come 1 to 2 years from now, yes, but I feel that they are either slightly undervalued or about right. When I get back to my computer I’ll include a better reasoning+quick analysis of their upcoming products", "score": 4, "replies": []}, {"body": " \n\nAlright, I have some time now.\n\nIntel is an interesting story, if do not mess up their plans for products, they could be very disruptive.\n\nLet's start with the good: Intel's XPUs:\n\nXPUs are essentially heterogeneous CPUs with various accelerators, GPUs, and HBM.[ https://s21.q4cdn.com/600692695/files/doc\\_presentations/2019/05/2019-Intel-Investor-Meeting-Renduchintala.pdf](https://s21.q4cdn.com/600692695/files/doc_presentations/2019/05/2019-Intel-Investor-Meeting-Renduchintala.pdf) (slide we will be looking at)\n\nFirst let's look at the most interesting slide (8th slide) we see a diagram of an XPU. This slide is interesting because of the implications of it. There are 16 XPU chips, if we look at this from a purely CPU workload, this PCB could have a total of 448 cores (if each XPU chip is counted as a 28 core Xeon) with another 16 HBM chips which would act as L4 cache. The black chips I do not know because the image included is far too low resolution, most likely, they are IO chips. If we take this as a truth, this would be a monster for Deep Learning applications. It is also important to note that the XPU chips could also be a combination of GPUs and CPUs whioch could be used for whatever the customer demands. Not only that, recently with the acquisitions of various companies over the past few years, we could see Intel utilize their technology to accelerate specific work loads. (please watch this video by AdoredTV he will do a much better explanations of this than I can do in a short post:[ https://www.youtube.com/watch?v=wADBkjr63oU](https://www.youtube.com/watch?v=wADBkjr63oU) )\n\nSecondly, we need to look at their 3d stacked chips: Ok, let's look at what we know: Foveros is essentially Intel's infinity fabric, meaing they can connect various chips together, meaning they can make special chips for companies to best suit their needs without having to make an entirely new design, this will allow chips to be cheaper as less RND has to go into these products, meaning higher profit margins. The issue with this is they are \\*still\\* on 14nm, so there is only so efficient you can make a die, meaning they will produce a heck of a lot of heat which is an issue if you want to make sure your chip does not explode. This is the reason why Intel needs to be on 10nm of 7nm for these 3d stacked chips to properly work. That being said, another advantage of 3d stacking is extremely low latency. so you can easily scale cores up to your thermal constraints and have massive cache to allow for an easy IPC bonus.\n\nOk onto the negatives\n\nThere is a lot to cover here so we will start with by far the most important segment of the market, the server space. Recently Intel has come under fire for their stagnation of increasing core counts whilst maintaining extremely high prices and poor support for PCIE lanes. This has been exasperated by the launch of Rome which, in almost all cases doubles the performance of the Intel counterpart at 5k less per socket. Furthermore, Rome has support for upto 128 lanes of PCIE Gen 4, which have double the bandwidth of Gen 3. This is an issue because having higher bandwidth allows for more accelerators and GPUs to be tacked onto a socket. Jumping back to the relative performance, briefly, it is also important to note that Intel has less than half the cores of AMD. To compound this, clock for clock, AMD is 13% faster which means that if you have a Zen 2 core running at 2.8 GHz, it will be equally as strong as an Intel core running at 3.164 GHz. It is also important to note that the Intel system with 28 cores will take roughly the same amount of power to run as a 64 core Rome system and as we know, efficiency is key in servers. \n\nAnother massive issue, which eclipses all other issues, are Intel’s insane security vulnerabilities. In the server space, Intel is a joke with regards to secuirity, in fact, if you look at their current vulnerabilities, you will see that there are currently 4 major vulnerabilities which will allow a person to gain access to the system without the server admins knowing. These vulnerabilities are: Specter, Meltdown, ZombieLoad, NetCAT (there are a total of 233 vulnerabilities associated with Intel and 15 associated with AMD). All of these attacks, aside from Meltdown cannot be mitigated by software updates, and the only way to prevent an attack would be disabling key functions of the product. In fact, if you own a server and take all of these security vulnerabilities into account and implement the protective measures, you would see a 60-80% decrease in server capacity (Note, AMD was affected by Specter and Meltdown, but it only resulted in a minimal decrease of performance in the single digits). If we look at the requirements placed on servers and take into the fact that they typically run at 100% capacity all the time, a 60% decrease in performance is a massive issue, therefore, customers are forced to buy more Intel products to keep up with demand, hence Intel’s constant chip shortages. From this we can see that the issues surrounding Intel’s server chips are massive, and come Zen 3, we will see a massive migration away from Intel in the server space unless they respond.\n\nMoving onto desktops and high-end desktops (HEDT) we se yet more issues. Intel has not released a truly new architecture since 2015 with Skylake. This is a problem because along with not being able to upgrade their architecture in any meaningful way, they are still on 14nm (Now dubbed 14nm+++), so they have issues with transistor density meaning their chips are a lot bigger than their counterparts offered by AMD. As previously discussed, the bigger a die, the more expensive it is to produce. We can also see that at the moment Intel is barely competing with AMD in terms of performance at a much higher thermal package and a much higher price. The issue with that is we can see that a lot more people are buying AMD products than Intel products ([AMD sells 79% of consumer processors](https://www.techradar.com/news/amd-ryzen-7-3700x-is-such-a-hit-it-almost-outsold-intels-entire-cpu-range)). This means that slowly, but surely, AMD is chipping away at Intel’s dominance, and with every penny AMD earns, Intel loses a penny.\n\nLet’s turn our heads now to Intel’s upcoming products next year. Chief among them is a 10 core Intel part that will run at a whopping 5GHz! This is complete nonsense, we will never see a 10 core part run at 5GHz due to the aforementioned issues with thermals at 14nm, most likely, we will see it run one or two cores at 4.8-4.9 GHz and have an all core turbo of maybe 4.5 GHz under liquid cooling. The only way Intel will get 5GHz is if they use exotic cooling, which they would never do… Right? [Oh wait....](https://www.forbes.com/sites/antonyleather/2018/06/08/intels-shady-tactics-revealed-pc-enthusiasts-furious-over-28-core-5ghz-processor/#84f5aa71ccd8) If we look at their upcoming server products their is nothing aside from a 400 watt TDP joke of a processor with a mere 56 cores, 8 less than AMD at almost double the power consumption. If you have been paying attention to the semiconductor space for a few years, this is Intel’s Bulldozer moment.\n\nWrote this really fast so am sorry if none of this makes any sense at all please ask questions and I’ll clarify.", "score": 5, "replies": [{"body": "14 nm is 8.226583624e-09 smoots\n\n10 nm is 1.6126431220770843e-08 cubic hogshead edges\n\n7 nm is 4.33114913e+26 planck lengths\n\n^^^[WHY](/r/UselessConversionBot/comments/1knas0/hi_im_useless/)", "score": 1, "replies": []}, {"body": "Wow, I understood some of this but it felt like a thorough read that INTC is not going to be doing well over the next year or so. Perhaps I'll buy some AMD, thanks :)", "score": 1, "replies": []}, {"body": "the question is when will intel deliver a viable 7nm part?\nwhen will they have a part that will compete with AMD EPYC?", "score": 1, "replies": [{"body": "2021-2022 earliest (2021 is VERY generous), we will have to see how density works out though, it could be competitive, but so far it is too early to tell.", "score": 1, "replies": [{"body": "so what datacenters would still be using Intel if they are overpriced and lower core density than AMD's offerings? are they in transition at this point?", "score": 1, "replies": [{"body": "Lots of legacy applications are made for Intel, I’ll link a podcast that is pretty good in terms of info if you are curious about the data center\n\n\nhttps://open.spotify.com/episode/0gmZp1xQzOIbvIuvtBkUvH?si=EH6HZV72Q9Sdd-ANXc6bwQ", "score": 1, "replies": []}]}]}]}]}]}, {"body": "Gotcha gonna buy NVDA puts now", "score": 2, "replies": []}, {"body": "Wow thanks for the in depth explanation. Do you have any links for me to learn more?", "score": 1, "replies": []}, {"body": "Good analysis, have some silver good sir", "score": 1, "replies": [{"body": "Thanks", "score": 1, "replies": []}]}]}, {"body": "I bought for 11 like 5 or 6 years ago. I hope my non existent children are happy inheriting it", "score": 7, "replies": []}, {"body": "[deleted]", "score": 8, "replies": [{"body": "This guy trades", "score": 2, "replies": []}]}, {"body": "I sold my shares yesterday locking in %20 or so. However I should have waited till today lol. So who knows. My plan was to sell now while it's high and wait for a terrible market day to go back in. I think it is still good long term.", "score": 7, "replies": [{"body": "Exactly what I did, but I sold a bit earlier. We can never know when's the top, so better lose out on some potential gain then be down. I wouldn't be surprised if Trump and China don't make a deal, pushing the market downward. And don't forget Brexit, Hong Kong, weak manufacturing, incoming recession in Europe, inverted yield curve, the Fed's \"not QE\" repo bail out (they'll continue until January 2020 they said), etc. \n\nAs for NVDA, there's AMD that's making a come back, although their GPU division hasn't been growing as fast as their CPU division. And there's also intel jumping into the GPU world in mid 2020, with some of the best graphics engineer in the world (they have Raja Koduri they stole from AMD) and can afford to pay them unlike AMD lol. \n\nSo with all of that in mind, I wouldn't hold NVDA if my time frame was 3-5 years. However, for the very long term, NVDA is still a VERY GOOD investment in my opinion.", "score": 3, "replies": []}]}, {"body": "I bought NVDA at $215 late November 2017. It went up to $290 then crashed. I am still HODL on to them for the long haul. The thing is do whatever you feel like, but have an exit strategy while you are already ahead.", "score": 4, "replies": [{"body": "Are you my twin? I am in at $215 as well", "score": 2, "replies": [{"body": "Yes, I am your twin. How are you?", "score": 7, "replies": []}]}]}, {"body": "They'll be manufacturing the brains of the robots that will rise up and kill us all. So yeah, good buy long term until they kill you.", "score": 4, "replies": []}, {"body": "People should be really careful when they talking about long term on Tech stocks. Tech is a highly competitive field, very few could survive and keep their crowns over a decade. Not saying NVDA is a bad company but don’t  be too optimistic and discussed about technology over 10 years. Nobody had clue that NOKIA would crashed so fast when iPhone arrived.", "score": 3, "replies": [{"body": "Does anyone remember RIM? (Blackberry)", "score": 2, "replies": []}]}, {"body": "Bought at $150 right before the last earnings. Was thinking of selling too. Might sell tomorrow.ade some money with options on them too", "score": 2, "replies": []}, {"body": "Long term they are the leaders in video graphics tech so theyre probably a fantastic long term (50 years) play.\n\nWho the fuck knows over the next two years where itll be.  You could sell out and slowly buy it back over the next year.\n\nDefinitely dont sell it if youre in it less than a year so you can get taxed at 20% instead of 40%ish", "score": 2, "replies": [{"body": "To get taxed at the maximum rate of 37% they’d need > $500,000 in taxable income. Based on the fact OP even asked, I’m going to guess they’re in a 22 or 24 bracket. But regardless OP, check your tax/capital gains brackets and see how much of an impact holding till 1Y would change any decision.", "score": 3, "replies": [{"body": "At what point do I pay less taxes than a school teacher? $500m?", "score": 1, "replies": [{"body": "Short term capital gains/Income: when you have less taxable income than them (there’s things that might lower your taxable income)\n\nLong term capital gains: situational depending on income. Look at the brackets\nhttps://www.investopedia.com/terms/c/capital_gains_tax.asp", "score": 1, "replies": [{"body": "Ok I'm going long on $TSLA when Elon meets Jensen", "score": 1, "replies": []}]}]}]}, {"body": "Don't I only get taxed if I take the money out of my brokerage account?", "score": 1, "replies": []}]}, {"body": "They are in the auto industry and neuarl networking, so probs good long.", "score": 2, "replies": []}, {"body": "It's kinda cyclical. You could day trade it and play the highs and lows.\n\nOtherwise, it seems good as a long-term stock", "score": 1, "replies": []}, {"body": "Longterm, its hard for me to think of a stock I am more certain will only appreciate.\n\nGaming has EXPLODED in popularity. Fortnite gets as many viewers as any professional sports match... a majority of these viewers are <15 and are going to grow up seeing video gaming as more mainstream than Baseball or football.  There is a reason the NFL is now pay twitch streamers to help advertise their games. And with Nvidia having presences at streams and conventions, they are going to be synonymous with esports IMO. \n\nAnd thats not speculating on their other ventures, AI, Automotive, etc etc at all.\n\nIm just personally annoyed as I wanted to put 20,000 into NVDA last week, but am waiting on transfer to get approved and woke up today to see its up 15% overall for me", "score": 1, "replies": []}, {"body": "I hold some shares in a retirement account, but not in my taxable account.  My taxable account actually has less volatile investments.  And if NVDA gets massive in 20  years, I'd rather pay zero taxes on it.", "score": 1, "replies": []}]}
